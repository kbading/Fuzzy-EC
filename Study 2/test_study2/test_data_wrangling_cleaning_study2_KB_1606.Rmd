---
title: "Data wrangling and cleaning -- WSW study 2 program test"
author: "Karoline Bading // Jérémy Béna"
date: $25^{th}$ of May 2023
output:
  html_document:
    toc: true
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, comment = NA)
```

# Set-up

## Call packages

```{r packages}
#Data wrangling and cleaning

#Load (or install and load) packages
require(pacman)
p_load('tidyverse', 'jsonlite', 'psych')
```

## Read the data

I used the data from the two studies on Jatos (wsw first run and wsw second run).

```{r read_data, message=FALSE, warning=FALSE}
# Read the text file from JATOS (first batch)...
read_file('test_data_2706.txt')%>%
#... split it into lines ...
 str_split('\n') %>% first() %>%
#... filter empty rows ...
 discard(function(x) x == '') %>%
#... parse JSON into a data.frame
 map_dfr(fromJSON, flatten=T) -> dat


```

There are `r length(unique(dat.1$url.srid))-1` participants in the "first-run" study and `r length(unique(dat.2$url.srid))-1` participants in the "second-run" study, for a total of `r length(unique(dat$url.srid))-1` participants.

# Data cleaning and wrangling

## Data cleaning

The dataset `dat` we now have contains a lot of columns we do not need, so we will select only the useful columns. In addition, some useful information (e.g., whether a participant declared they were serious) is only available in one row, which is problematic to, e.g., exclude such a participant -- so we repeat `url.srid`, `serious`, and `pay_attention` on each row of each participant.

```{r data_cleaning}
table(dat$pay_attention) 
table(dat$serious)
table(dat$order) #some participants in "eval_first", others in "mem_first"

#checker whether counterbalancing worked as intended in test phase
dat_check_counterbalancing = dat %>% filter(sender=="mem_first_sequence" | sender=="eval_first_sequence")

table(dat_check_counterbalancing$sender, dat_check_counterbalancing$ended_on, dat_check_counterbalancing$order) #ok

#repeat url.srid (participant number), pay attention, and serious on every line of each participant; then select only useful variables
dat = dat %>%
   fill(url.srid, .direction = "down") %>% 
  group_by(url.srid) %>% 
  fill(consent, serious, pay_attention, .direction = "down") %>%
  fill(serious, pay_attention, .direction = "up") %>% 
  select(url.srid, sender, duration, ended_on, serious, pay_attention, response, response_action #general information
         , count_trial_learning, cs, us, us_valence, uss #learning phase
         , count_trial_memory, idtarg, reco_resp, source_mem  #memory phase
         , count_trial_ratings, cs_rating #rating phase 
         , order #counterbalancing order in the test phase
         ) 
```

## Make the final dataset

In the experiment, there were three main tasks (learning phase; recognition/source memory task; rating task). For each task, we create a dataset to select the critical information and rearrange the data if necessary. The main idea is to create a final dataset with 48 (24 CSs paired with USs in the learning phase + 24 new neutral stimuli) \* N_participants rows. At each CS \* Participant level, all responses provided by the participants will be available (e.g., for a given CS and participant, the recognition, CS-US pairing memory, and rating responses).

### Learning phase

Besides making a dataset for the learning phase, we test whether 24 US and 24 unique CS-US pairs displayed six times each for each participant.

```{r learning}
#learning phase
#keep only the rows of the conditioning phase trials
dat_learning = dat %>% filter(sender == "learning_trial_option1")  %>%
  select(url.srid, count_trial_learning, cs, us,us_valence, uss)

#check if we have all the different USs (24) across participants 
length(unique(dat_learning$us)) #we have

#check if, for each participant, all USs were used
count_us = unique(dat_learning[,c('url.srid','us')])

dat_count_us = count_us %>%                           
  group_by(url.srid) %>%
  summarise(count = n_distinct(us))

table(dat_count_us$count==24) #yes

#check if for each participant, all different CSs were used
count_cs = unique(dat_learning[,c('url.srid','cs')])

#count if we have only 24 unique cs-us pairs between participants
count_pairings = unique(dat_learning[,c('url.srid','cs','us')])
count_pairings$cs_us = paste0(count_pairings$cs, count_pairings$us)

count_pairings %>%                           
 group_by(url.srid) %>%
  summarise(count = n_distinct(cs_us))
#seems ok! 24 unique CS-US pairs
```

# check if each cs-us pair is presented once in all 24-trial sets of learning procedure

```{r}
dat_learning$block <- ifelse(dat_learning$count_trial_learning %in% c(0:23)
                             ,1
                             ,ifelse(dat_learning$count_trial_learning %in% c(24:47)
                                     ,2
                                     ,ifelse(dat_learning$count_trial_learning %in% c(48:71)
                                             ,3
                                             ,ifelse(dat_learning$count_trial_learning %in% c(72:95)
                                                     ,4
                                                     ,ifelse(dat_learning$count_trial_learning %in% c(96:119)
                                                                                                      ,5,6)))))

table(dat_learning$url.srid,dat_learning$block)

count_cs_block = unique(dat_learning[,c('url.srid','cs','block')])

dat_count_cs_block = count_cs_block %>%                           
  group_by(url.srid,block) %>%
  summarise(count = n_distinct(cs))

table(dat_count_cs_block$count==24) #7*3=21, all good

count_us_block = unique(dat_learning[,c('url.srid','us','block')])

dat_count_us_block = count_us_block %>%                           
  group_by(url.srid,block) %>%
  summarise(count = n_distinct(us))

table(dat_count_us_block$count==24) #all good too

count_pairings_block = unique(dat_learning[,c('url.srid','block','cs','us')])
count_pairings_block$cs_us = paste0(count_pairings_block$cs, count_pairings_block$us)

dat_count_pairings_block = count_pairings_block %>%                           
 group_by(url.srid,block) %>%
  summarise(count = n_distinct(cs_us))

table(dat_count_pairings_block$count==24) #all good too

```

### Memory task

```{r memory}
dat_reco = dat %>% filter(sender=="recognition_trial") %>%
  select(url.srid, count_trial_memory, cs, us, us_valence, uss, idtarg, reco_resp, order)

dat_source = dat %>% filter(sender=="source_trial") %>%
  select(url.srid, count_trial_memory, cs, us, us_valence, uss, idtarg, source_mem, order)
```

#### 48 unique CSs in the memory task?

```{r}
#check if, for each participant, all CS (48) in the recognition task
count_us_mem = unique(dat_reco[,c('url.srid','cs')])

dat_count_cs = count_us_mem %>%                           
  group_by(url.srid) %>%
  summarise(count = n_distinct(cs))

table(dat_count_cs$count==48) 

table(dat_reco$cs, dat_reco$url.srid)
```

### Ratings

```{r ratings}
dat_ratings = dat %>% filter(sender=="rating_trial_version1") %>%
  select(url.srid, count_trial_ratings, cs, us, us_valence, cs_rating, serious, pay_attention, order)
```

#### 48 unique CSs in the rating task?

```{r}
#check if, for each participant, all CS (48) in the rating task
count_us_rat = unique(dat_ratings[,c('url.srid','cs')])

dat_count_cs_rat = count_us_rat %>%                           
  group_by(url.srid) %>%
  summarise(count = n_distinct(cs))

table(dat_count_cs_rat$count==48) #no, 24 only displayed multiple times

table(dat_ratings$cs, dat_reco$url.srid) #problem here
```

### Put the memory and rating datasets together

We don't need the `dat_learning` dataset as the relevant information it contains also appears in the other datasets (specifically, the `cs`, `us`, `uss`, `idtarg` variables).

```{r make_dataset}
#make the final data set -- based on multiple "full_join" to integrate all conditions and responses based on ppts, cs, us

#join recognition and source memory responses 
dat_mem = full_join(dat_reco, dat_source,
                               by = c("url.srid"="url.srid", "cs" = "cs", "us"="us", "uss"="uss", "idtarg"="idtarg", "us_valence"="us_valence", "count_trial_memory"="count_trial_memory", "order"="order"))

#join memory dataset and rating dataset
dat_final = full_join(dat_mem, dat_ratings
                               , by = c("url.srid"="url.srid", "cs" = "cs", "us"="us","us_valence"="us_valence", "order"="order"))
```

# Write the final dataset (for use in the analysis `.Rmd`)

```{r write_data}
#write the final dataset we will use for analyses in another R script
saveRDS(dat_final, "test_data_2706.RDS") #RDS can handle lists such as in the `uss` list
```
