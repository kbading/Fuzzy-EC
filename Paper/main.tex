% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  man,floatsintext]{apa6}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\ifLuaTeX
\usepackage[bidi=basic]{babel}
\else
\usepackage[bidi=default]{babel}
\fi
\babelprovide[main,import]{english}
% get rid of language-specific shorthands (see #6817):
\let\LanguageShortHands\languageshorthands
\def\languageshorthands#1{}
% Manuscript styling
\usepackage{upgreek}
\captionsetup{font=singlespacing,justification=justified}

% Table formatting
\usepackage{longtable}
\usepackage{lscape}
% \usepackage[counterclockwise]{rotating}   % Landscape page setup for large tables
\usepackage{multirow}		% Table styling
\usepackage{tabularx}		% Control Column width
\usepackage[flushleft]{threeparttable}	% Allows for three part tables with a specified notes section
\usepackage{threeparttablex}            % Lets threeparttable work with longtable

% Create new environments so endfloat can handle them
% \newenvironment{ltable}
%   {\begin{landscape}\centering\begin{threeparttable}}
%   {\end{threeparttable}\end{landscape}}
\newenvironment{lltable}{\begin{landscape}\centering\begin{ThreePartTable}}{\end{ThreePartTable}\end{landscape}}

% Enables adjusting longtable caption width to table width
% Solution found at http://golatex.de/longtable-mit-caption-so-breit-wie-die-tabelle-t15767.html
\makeatletter
\newcommand\LastLTentrywidth{1em}
\newlength\longtablewidth
\setlength{\longtablewidth}{1in}
\newcommand{\getlongtablewidth}{\begingroup \ifcsname LT@\roman{LT@tables}\endcsname \global\longtablewidth=0pt \renewcommand{\LT@entry}[2]{\global\advance\longtablewidth by ##2\relax\gdef\LastLTentrywidth{##2}}\@nameuse{LT@\roman{LT@tables}} \fi \endgroup}

% \setlength{\parindent}{0.5in}
% \setlength{\parskip}{0pt plus 0pt minus 0pt}

% Overwrite redefinition of paragraph and subparagraph by the default LaTeX template
% See https://github.com/crsh/papaja/issues/292
\makeatletter
\renewcommand{\paragraph}{\@startsection{paragraph}{4}{\parindent}%
  {0\baselineskip \@plus 0.2ex \@minus 0.2ex}%
  {-1em}%
  {\normalfont\normalsize\bfseries\itshape\typesectitle}}

\renewcommand{\subparagraph}[1]{\@startsection{subparagraph}{5}{1em}%
  {0\baselineskip \@plus 0.2ex \@minus 0.2ex}%
  {-\z@\relax}%
  {\normalfont\normalsize\itshape\hspace{\parindent}{#1}\textit{\addperi}}{\relax}}
\makeatother

\makeatletter
\usepackage{etoolbox}
\patchcmd{\maketitle}
  {\section{\normalfont\normalsize\abstractname}}
  {\section*{\normalfont\normalsize\abstractname}}
  {}{\typeout{Failed to patch abstract.}}
\patchcmd{\maketitle}
  {\section{\protect\normalfont{\@title}}}
  {\section*{\protect\normalfont{\@title}}}
  {}{\typeout{Failed to patch title.}}
\makeatother

\usepackage{xpatch}
\makeatletter
\xapptocmd\appendix
  {\xapptocmd\section
    {\addcontentsline{toc}{section}{\appendixname\ifoneappendix\else~\theappendix\fi\\: #1}}
    {}{\InnerPatchFailed}%
  }
{}{\PatchFailed}
\keywords{keywords\newline\indent Word count: X}
\usepackage{csquotes}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Memory specificity in evaluation conditioning: a `Who said what' approach},
  pdfauthor={Jéréline Benading1 \& Klaus Rothermund2},
  pdflang={en-EN},
  pdfkeywords={keywords},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Memory specificity in evaluation conditioning: a `Who said what' approach}
\author{Jéréline Benading\textsuperscript{1} \& Klaus Rothermund\textsuperscript{2}}
\date{}


\shorttitle{Memory specificity in EC}

\authornote{

Correspondence concerning this article should be addressed to Jéréline Benading, . E-mail: \href{mailto:karoline.bading@uni-jena.de}{\nolinkurl{karoline.bading@uni-jena.de}}

}

\affiliation{\vspace{0.5cm}\textsuperscript{1} Université Agnostique de Louvain-la-Jena\\\textsuperscript{2} Friedrich Schiller University Jena}

\abstract{%
BLABLABLABLABLA
}



\begin{document}
\maketitle

\emph{General anticipated outline of the introduction}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Context, EC, contingency awareness; at encoding; at retrieval/response; theoretical/applied implications
\item
  Lack of evidence for EC in the absence of awareness (at encoding); at retrieval: memory for US Valence vs.~for US identity; past research (Hütter; Pleyers; Stahl\ldots); critical role of US valence memory in EC but not of US identity memory (``\emph{when valence awareness is controlled for, identity awareness does not predict the EC outcome any longer}'')
\item
  Limitations of previous approaches to separate US identity memory and US valence memory, including: measurement error (multiple tasks or scores to estimate US valence and US identity memory), no distinction between memory processes and response biases; no distinction between recognition memory and item-item (associative memory)
\item
  Current approach: US identity vs.~US valence memory: a specificity question. Distinguish between more or less specific memory: who-said-what (wsw) paradigm and model -- estimate recognition memory, US identity memory, US valence memory, and response biases in a single (direct memory) task. General logic of wsw, previous results (Klauer \& Wegener; Bell, Buchner\ldots) and parameter validation (Klauer \& Wegener).
\item
  Current research: use wsw in EC to test in a new way the contribution of specific (US identity) and less specific (US valence) memory to EC effect: (1) Check model fit, estimate parameters, estimate their contribution to responses in the memory task; (2) then regress CS evaluations/EC effect on the estimates.
\end{enumerate}

\hypertarget{methods}{%
\section{Methods}\label{methods}}

We report how we determined our sample size, all data exclusions, all manipulations, and all measures. The preregistration, experiment program, data, and analyses are publicly available on the Open Science Framework at: \url{https://osf.io/rqkvy/}.

The study project was approved by the ethics committee of \emph{{[}Institution Redacted{]}} (\emph{{[}ID Redacted{]}}).

\hypertarget{participants-and-design}{%
\subsection{Participants and design}\label{participants-and-design}}

The experiment used a 2 (US valence: Positive vs.~Negative vs.~None) x 2 (Task order: Evaluation first vs.~Memory first) mixed design, with US valence manipulated within participants and Task order manipulated between participants.

We recruited 172 participants (50\(\%\) female; \(M_{age} =\) 39.59; \(SD_{age} =\) 13.23), our targeted sample size, online on Prolific. Participants were English speakers, had an approval rate of at least 90\% and at least 100 previous submissions, and did not take part in previous evaluative conditioning studies we conducted on Prolific. Data were unavailable for one participant, and we excluded 5 participants declaring that they did not pay attention or did not take their responses seriously. This resulted in a final sample size of 166 participants (\(n =\) 70 in the Evaluation first condition and \(n =\) 96 in the Memory first condition).

To determine sample size, we set \(\alpha\) to .05, and we aimed for a statistical power of at least \(80\%\) to detect an Evaluative Conditioning effect as small as Cohen's \(d = 0.2\) in a one-sided paired sample \emph{t}-test (IV: US valence; DV: evaluative ratings). An analysis with the R package \emph{pwr} (version 1.3-0; Champely, 2020) showed that we needed 156 participants. A sample size of \emph{N} = 156 also provided \(80%
\) power to detect correlations \(rs \geq .22\) (e.g., between parameter estimates and evaluative conditioning scores). To avoid a final sample smaller than the targeted sample size after applying the exclusion criteria, we increased this estimate by 10\%, resulting in 172 participants.

\hypertarget{materials-and-procedure}{%
\subsection{Materials and procedure}\label{materials-and-procedure}}

We programmed the experiment with lab.js (Henninger et al., 2022). We exported the study to an HTTPS-protected website with JATOS (Lange et al., 2015).

\hypertarget{stimuli}{%
\subsubsection{Stimuli}\label{stimuli}}

As neutral stimuli, we used 54 5- to 7-letter nonwords (all made of a combination of vowels and consonants; e.g., `\emph{botsy}'; `\emph{ampfong}') used in a previous study (Stahl \& Bading, 2020). At the participant level, 24 nonwords were used as CSs (paired with USs in the learning phase) and 24 were new (i.e., presented only in the test phase).

The USs were 24 color images of animals (e.g., a cockroach), scenes (e.g., a rainbow), and objects (e.g., a knife) selected from the Open Affective Standardized Image Set (OASIS; Kurdi et al., 2017). Based on OASIS ratings (on a 7-point Likert scale), 12 images were positive (\(M_{valence} = 5.88\); \(SD_{valence}\) = 0.24; \(M_{arousal} = 4.10\); \(SD_{arousal} = 0.50\)) and 12 were negative (\(M_{valence} = 2.05\); \(SD_{valence} = 0.32\); \(M_{arousal} = 4.27\); \(SD_{arousal} = 0.52\)). Positive USs were significantly more positive than negative USs, Welch's \(t(20.23) = 33.36, p < .001\). Positive and negative USs did not significantly differ in arousal, Welch's \(t(21.96) = 0.82, p = .419\).

\hypertarget{learning-phase}{%
\subsubsection{Learning phase}\label{learning-phase}}

After providing their informed consent, participants entered the learning phase. Participants were told that they would see pairs made of one nonword (the CSs; on the center-left of the screen) and one image (the USs on the center-right of the screen). Participants had to pay close attention to each pair.

Twenty-four CS-US pairs were presented three times each in a random order (block-wise) for 1000 milliseconds (separated by an inter-trial interval of 1000 ms), resulting in 72 trials. For each participant, the 24 CSs were randomly drawn from the pool of 54 nonwords. Each CS was paired with one specific US. The CSs were displayed in a sans-serif font (font-size: 40). The dimensions of the USs were 250 pixels (width) and 200 pixels (height).

\hypertarget{test-phase}{%
\subsubsection{Test phase}\label{test-phase}}

After the learning phase, participants entered the test phase. Participants performed two tasks: an evaluative rating task and a memory task. Participants were randomly assigned to one of the two Task order conditions. In the Evaluation first condition, participants performed the evaluative rating task and then the memory task. The order was reversed in the Memory first condition: participants performed the memory task and then the evaluative rating task. The exact wording of the tasks slightly differed as a function of Task order.

\hypertarget{evaluative-rating-task}{%
\paragraph{Evaluative rating task}\label{evaluative-rating-task}}

In the evaluative rating task, the 24 CSs presented in the learning phase and 24 new nonwords (randomly drawn from the remaining pool of 30 nonwords) were displayed individually once in a random order without time limit. Participants rated how positive or negative they found the nonwords on a 8-point Likert scale ranging from 1 ``very negative'' to 8 ``very positive.'' The 48 trials were separated by 500-ms inter-trial intervals.

\hypertarget{memory-task}{%
\paragraph{Memory task}\label{memory-task}}

In the memory task, the 24 CSs presented in the learning phase and 24 new nonwords (identical to the ones displayed in the evaluative rating task) were displayed individually once in a random order without time limit.

Each of the trials began with a recognition memory task. Participants were asked whether the nonwords were part of the pairs presented in the learning phase (response options: ``Yes (old)''; ``No (new)'').

If participants responded ``No (new),'' the next recognition memory trial began after a 500-ms inter-trial interval. If participants responded ``Yes (old),'' a new screen including the same nonword appeared after a 500-ms blank screen, and participants had to select the specific image that the nonword was paired with. Participants were instructed to click on the specific image if they remembered it or to guess the correct image if they could not remember the exact image. Eight images (all from the learning phase) were displayed in two rows of four images. For nonwords that were correctly recognized (hits), the correct US was presented with 7 randomly selected distractors (3 images of the same valence as the correct US; 4 images of the opposite valence). All the USs were allocated to a random position. For nonwords that were incorrectly recognized (false alarms), 8 USs, half positive and half negative, were randomly selected and allocated to a random position.

\hypertarget{check-measures}{%
\paragraph{Check measures}\label{check-measures}}

After the test phase, we administered an attention check and a seriousness check. In the attention check, we asked participants whether they paid attention to the nonwords and images presented throughout the study (Yes/No response). Participants were told that their response would not affect their payment.

In the seriousness check based on Aust et al.~(2013), participants read:

\emph{``It would be very helpful if you could tell us at this point whether you have taken the requested responses seriously, so that we can use your answers for our scientific analysis, or whether you were just clicking through to take a look at the survey? (again, this will not affect your payment).''}

The response options were \emph{``I have taken the requested responses seriously''} and \emph{``I have just clicked through, please discard my data''}. We used the answers to the attention and seriousness checks as exclusion criteria (see the Participants and design section).

Participants then had the chance to comment on the study. Finally, participants were thanked and debriefed.

\hypertarget{data-processing-and-analyses}{%
\subsection{Data processing and analyses}\label{data-processing-and-analyses}}

\textbf{{[}To be done{]}}

\hypertarget{results}{%
\section[Results]{\texorpdfstring{Results\footnote{All analyses were conducted with R (R Core Team, 2021). We used the packages XXX (), XXX (), XXX (), XXX (), XXX (), XXX (), XXX ()\ldots{}}}{Results}}\label{results}}

\hypertarget{preregistered-analyses-on-evaluative-ratings}{%
\subsection{Preregistered analyses on evaluative ratings}\label{preregistered-analyses-on-evaluative-ratings}}

We report the analyses we conducted on evaluative ratings. We averaged evaluative ratings as a function of US valence (Positive, Negative, None) and Task order (Evaluation first, Memory first). For each participant, we calculated an Evaluative Conditioning (EC) score, which is their mean evaluative rating on CSs paired with positive USs minus their mean evaluative rating on CSs paired with negative USs (negative scores indicate higher evaluations on negatively paired vs.~positively paired CSs; positive scores indicate higher evaluations on positively vs.~negatively paired CSs).

First, we conducted a between-participants ANOVA on EC scores with Task order as the only factor. We tested whether the grand mean was above 0 by calculating the F-test of the intercept. A grand mean above 0 would indicate that, overall, we replicated the EC effect. In line with the preregistration, we divided the \emph{p}-value of this test by two to perform a one-tailed test, as the grand mean of EC scores was above 0 (\(M =\) 0.72; \(SD =\) 0.97). The \emph{F}-test was significant, , showing that we replicated the EC effect. The effect of Task order was not significant\footnote{As preregistered, we divided the \emph{p}-value by two to perform a one-tailed version of the test (similar to \emph{t}-tests) because means of EC scores are descriptively larger in the Evaluation first (\(M =\) 0.80; \(SD =\) 0.87) than Memory first (\(M =\) 0.66; \(SD =\) 1.03) condition. EC scores were above 0 both in the Evaluation first condition, \(t(69) = 7.76\), \(p < .001\), \(d =\) 0.93, 90\% CI = {[}0.69, 1.16{]} and in the Memory first condition, \(t(95) = 6.22\), \(p < .001\), \(d =\) 0.63, 90\% CI = {[}0.45, 0.82{]}.}, \(F(1, 164) = 0.94\), \(p = .334\), \(\hat{\eta}^2_G = .006\), 90\% CI \([.000, .040]\), which means that performing the evaluative rating task before or after the memory task did not significantly change the EC effect.

\begin{figure}
\centering
\includegraphics{main_files/figure-latex/plot_us_valence_order-1.pdf}
\caption{(\#fig:plot\_us\_valence\_order)Mean evaluative ratings (and 95\% error bars) as a function of US valence and Task order.}
\end{figure}

Complementarily, we also conducted a 3 (US valence) x 2 (Task order) mixed ANOVA on evaluative ratings (see Figure~@ref(fig:plot\_us\_valence\_order)). Different from the ANOVA above, evaluative ratings on unpaired nonwords can be compared with evaluations in other conditions. The main effect of US valence was significant, \(F(2, 328) = 68.83\), \(p < .001\), \(\hat{\eta}^2_G = .156\), 90\% CI \([.099, .214]\). We followed-up on the ANOVA by conducting multiple comparisons (Bonferroni-corrected) based on the full model: evaluative ratings were higher for positively paired CSs compared with new nonwords, \(t(164) = -9.94, p < .001, d = 0.75, 95\%\) CI \(= [0.58, 0.92]\), and compared with negatively-paired CSs, \(t(164) = -9.61, p < .001, d = 0.74, 95\%\) CI \(= [0.57, 0.91]\). Evaluative ratings were not significantly different for negatively-paired CSs and for nonwords, \(t(164) = -0.39, p = .922, d = 0.02, 95\%\) CI \(= [-0.13, 0.17]\). The main effect of Task order was not significant, \(F(1, 164) = 0.04\), \(p = .844\), \(\hat{\eta}^2_G = .000\), 90\% CI \([.000, .010]\), nor was the interaction between US valence and Task order, \(F(2, 328) = 1.81\), \(p = .166\), \(\hat{\eta}^2_G = .005\), 90\% CI \([.000, .021]\).

\hypertarget{preregistered-analyses-on-memory-performance}{%
\subsection{Preregistered analyses on memory performance}\label{preregistered-analyses-on-memory-performance}}

\hypertarget{model-fit-and-parameter-estimates}{%
\subsubsection{Model fit and parameter estimates}\label{model-fit-and-parameter-estimates}}

\begin{table}[tbp]

\begin{center}
\begin{threeparttable}

\caption{\label{tab:model-performance}Experiment 1: Absolute fit and WAIC for the hierarchical extensions of unrestricted and restricted variants of the who-said-what model.}

\scriptsize{

\begin{tabular}{lrrrrrrrr}
\toprule
  & \multicolumn{1}{c}{Unrestricted} & \multicolumn{1}{c}{$D = 0$} & \multicolumn{1}{c}{$C_{\mathrm{pos}} = 0$} & \multicolumn{1}{c}{$C_{\mathrm{neg}} = 0$} & \multicolumn{1}{c}{$d_{\mathrm{pos}} = 0$} & \multicolumn{1}{c}{$d_{\mathrm{neg}} = 0$} & \multicolumn{1}{c}{$b = .5$} & \multicolumn{1}{c}{$a = .5$}\\
\midrule
Goodness of fit: Means &  &  &  &  &  &  &  & \\
\ \ \ $T_1^{\mathrm{observed}}$ & 0.05 & 74.02 & 9.09 & 10.07 & 0.04 & 0.05 & 6.92 & 0.05\\
\ \ \ $T_1^{\mathrm{expected}}$ & 0.04 & 0.05 & 0.04 & 0.04 & 0.04 & 0.04 & 0.05 & 0.04\\
\ \ \ $p$ & .403 & < .001 & < .001 & < .001 & .592 & .373 & < .001 & .389\\
Goodness of fit: Covariances &  &  &  &  &  &  &  & \\
\ \ \ $T_2^{\mathrm{observed}}$ & 2.53 & 724.63 & 121.70 & 110.23 & 2.50 & 2.66 & 39.18 & 2.66\\
\ \ \ $T_2^{\mathrm{expected}}$ & 2.45 & 2.19 & 2.45 & 2.47 & 2.50 & 2.48 & 2.68 & 2.49\\
\ \ \ $p$ & .461 & < .001 & < .001 & < .001 & .484 & .417 & < .001 & .420\\
Relative predictive accuracy &  &  &  &  &  &  &  & \\
\ \ \ $\mathrm{WAIC}$ & 3,695.99 & 11,200.27 & 5,094.10 & 5,288.79 & 3,695.01 & 3,695.48 & 5,632.61 & 3,696.15\\
\ \ \ $\mathit{SE}$ & 71.33 & 304.31 & 163.84 & 164.93 & 71.43 & 71.54 & 94.70 & 71.59\\
\bottomrule
\end{tabular}

}

\end{threeparttable}
\end{center}

\end{table}

\begin{table}[tbp]

\begin{center}
\begin{threeparttable}

\caption{\label{tab:exp1-param}Parameter estimates (with 95\% credible intervals) based on a hierarchical extension of the unrestricted who-said-what model with task order as categorical predictor of individual parameter estimates.}

\begin{tabular}{lccccccr}
\toprule
 & \multicolumn{2}{c}{overall} & \multicolumn{2}{c}{evaluation first} & \multicolumn{2}{c}{memory first}  &\\
\cmidrule(r){2-3} \cmidrule(r){4-5} \cmidrule(r){6-7}
Parameter & \multicolumn{1}{c}{$M$} & \multicolumn{1}{c}{95\% CI} & \multicolumn{1}{c}{$M$} & \multicolumn{1}{c}{95\% CI} & \multicolumn{1}{c}{$M$} & \multicolumn{1}{c}{95\% CI} & \multicolumn{1}{c}{$\:p$}\\
\midrule
$D$ & .454 & {}[.413, .495] & .396 & {}[.341, .452] & .513 & {}[.454, .572] & .002\\
$C_{\mathrm{pos}}$ & .667 & {}[.574, .757] & .641 & {}[.514, .760] & .690 & {}[.565, .802] & .272\\
$C_{\mathrm{neg}}$ & .808 & {}[.713, .899] & .793 & {}[.661, .906] & .818 & {}[.690, .920] & .368\\
$d_{\mathrm{pos}}$ & .049 & {}[.001, .176] & .055 & {}[.000, .290] & .080 & {}[.000, .365] & .382\\
$d_{\mathrm{neg}}$ & .118 & {}[.003, .382] & .167 & {}[.001, .692] & .121 & {}[.000, .516] & .423\\
$b$ & .135 & {}[.107, .165] & .212 & {}[.162, .266] & .081 & {}[.056, .110] & < .001\\
$a$ & .482 & {}[.439, .524] & .470 & {}[.414, .527] & .493 & {}[.437, .549] & .269\\
\bottomrule
\addlinespace
\end{tabular}

\begin{tablenotes}[para]
\normalsize{\textit{Note.} One-sided $p$ values}
\end{tablenotes}

\end{threeparttable}
\end{center}

\end{table}

The who-said-what MPT model (with \(D_{\mathrm{positive}}=D_{\mathrm{negative}}=D_{\mathrm{new}}\) and \(1/n=.25\)) was fit to the whole sample. Task order (memory first vs.~evaluation first) was included as a categorical predictor of individual parameter estimates.

The model fit the data well, \(T_1^{\mathrm{observed}} = 0.05\), \(T_1^{\mathrm{expected}} = 0.04\), \(p = .403\), \(T_2^{\mathrm{observed}} = 2.53\), \(T_2^{\mathrm{expected}} = 2.45\), \(p = .461\), and was therefore used as the baseline model to assess loss of model fit due to parameter restrictions.
Measures of (absolute and relative) model fit for the baseline model (and restricted model variants) are reported in Table~\ref{tab:model-performance}.
Parameter estimates based on the baseline model can be found in Table~\ref{tab:exp1-param}.

The discrimination parameter \(D\) was \(.454\) on average.
A restricted who-said-what model setting the \(D\) parameter to zero produced inadequate fit, \(T_1^{\mathrm{observed}} = 74.02\), \(T_1^{\mathrm{expected}} = 0.05\), \(p < .001\), \(T_2^{\mathrm{observed}} = 724.63\), \(T_2^{\mathrm{expected}} = 2.19\), \(p < .001\), and a WAIC of \(11,200.27\).
The WAIC of the restricted model was more than 10 points higher than the WAIC of the baseline model (\(\text{WAIC}_{baseline}=3,695.99\)), indicating that the \(D\) parameter cannot be set to zero without loss of model fit.

The \(C\) parameter for positively (negatively) paired CSs was \(.666\) (\(.864\)) on average.
A restricted who-said-what model setting \(C_{\mathrm{positive}}\) (\(C_{\mathrm{negative}}\)) to zero produced inadequate fit and a WAIC of \(5,094.10\) (\(5,288.79\)).
The WAIC values were again more than 10 points higher than the WAIC of the baseline model, indicating that neither \(C_{\mathrm{positive}}\) nor \(C_{\mathrm{negative}}\) parameter can be set to zero without loss of model fit.

The \(d\) parameter for positively (negatively) paired CSs was \(.049\) (\(.118\)) on average.
A restricted who-said-what model setting \(d_{\mathrm{positive}}\) (\(d_{\mathrm{negative}}\)) to zero produced adequate fit and a WAIC of \(3,695.01\) (\(3,695.48\)).
The WAIC values were almost identical to the WAIC of the baseline model, indicating that both \(d_{\mathrm{positive}}\) and \(d_{\mathrm{negative}}\) can be set to zero without loss of model fit.

The \(b\) parameter (indicating a bias for responding ``old'' in the recognition task) was \(.135\) on average.
A restricted who-said-what model setting the \(b\) parameter to \(.5\) produced inadequate fit and a \(WAIC\) of \(5,632.61\).
The WAIC difference between the models (restricted vs.~baseline) was again larger than 10, indicating that the \(b\) parameter cannot be set to \(.5\) without loss of model fit.

Finally, the \(a\) parameter (indicating a bias for selecting a positive US in the recollection task) was \(.482\) on average.
A restricted who-said-what model setting the \(a\) parameter to \(.5\) produced adequate fit and a WAIC of \(3,696.15\).
The WAIC was almost identical to the WAIC of the baseline model, indicating that the \(a\) parameter can be set to \(.5\) without loss of model fit.

\hypertarget{effects-of-task-order-on-parameter-estimates}{%
\subsubsection{Effects of task order on parameter estimates}\label{effects-of-task-order-on-parameter-estimates}}

MPT parameters (from the baseline model) as a function of task order are reported in Table~\ref{tab:exp1-param}.
For each MPT parameter, we calculated the posterior difference between group means and its associated Bayesian \(p\)~values (see Table~\ref{tab:exp1-param}).
For the \(D\) parameter, the group mean in the Memory first condition was substantially higher than the group mean in the Evaluation first condition.
For the \(b\) parameter, the effect of task order was reversed: the group mean was substantially higher in the Evaluation first condition than in the Memory first condition.
For the remaining parameters, the posterior difference between group mean was insubstantial.

\hypertarget{preregistered-analyses-on-evaluations-as-a-function-of-mpt-parameter-estimates}{%
\subsection{Preregistered analyses on evaluations as a function of MPT parameter estimates}\label{preregistered-analyses-on-evaluations-as-a-function-of-mpt-parameter-estimates}}

\hypertarget{evaluative-conditioning-effects}{%
\subsubsection{Evaluative Conditioning effects}\label{evaluative-conditioning-effects}}

As preregistered, we calculated several linear models including different sets of MPT parameters as predictors.
None of the reported models included \(C_{pos}\) and \(C_{neg}\) as separate predictors; instead, we used the individual mean of the two parameter estimates (denoted as \(C\) hereafter).
This departure from the preregistration aims at reducing multicollinearity between predictors (since the bivariate correlation between \(C_{pos}\) and \(C_{neg}\) turned out to be extremely high, \(r = .96\), 95\% CI \([.95, .97]\), \(t(164) = 45.21\), \(p < .001\)).
As preregistered, we also calculated variance inflation factors (VIFs) for all predictors included in a given model.
If the VIF of \(D\), \(b\) or \(a\) exceeded 5, we calculated a follow-up model without the respective MPT parameter(s) as predictor(s) of individual EC effects.
This analytical strategy was adopted to reduce multicollinearity with the MPT parameters that should be most directly related to EC (\(C\), \(d_{pos}\) and \(d_{neg}\)).

\begin{table}[tbp]

\begin{center}
\begin{threeparttable}

\caption{\label{tab:unnamed-chunk-19}Model 1: Linear model predicting individual EC effects from $D$, $C$, $d_{pos}$, $d_{neg}$, $b$ and $a$.}

\begin{tabular}{lrrrrrr}
\toprule
Predictor & \multicolumn{1}{c}{$b$} & \multicolumn{1}{c}{95\% CI} & \multicolumn{1}{c}{$t$} & \multicolumn{1}{c}{$\mathit{df}$} & \multicolumn{1}{c}{$p$} & \multicolumn{1}{c}{VIF}\\
\midrule
Intercept & 0.83 & {}[0.52, 1.14] & 5.25 & 152 & < .001 & ---\\
$D$ & 2.32 & {}[0.84, 3.81] & 3.09 & 152 & .002 & 5.31\\
$C$ & 0.77 & {}[-0.72, 2.26] & 1.02 & 152 & .307 & 8.65\\
$d_{\mathrm{pos}}$ & -1.03 & {}[-15.76, 13.70] & -0.14 & 152 & .890 & 8.1\\
$d_{\mathrm{neg}}$ & 8.07 & {}[-0.02, 16.17] & 1.97 & 152 & .051 & 6.16\\
$b$ & -0.89 & {}[-2.21, 0.43] & -1.32 & 152 & .187 & 2.26\\
$a$ & 1.08 & {}[-18.58, 20.75] & 0.11 & 152 & .913 & 10.07\\
Order1 & 0.09 & {}[-0.23, 0.40] & 0.54 & 152 & .589 & NA\\
D c $\times$ Order1 & -1.12 & {}[-2.61, 0.37] & -1.49 & 152 & .140 & NA\\
Cpn c $\times$ Order1 & 0.28 & {}[-1.21, 1.77] & 0.38 & 152 & .708 & NA\\
Dpos c $\times$ Order1 & 13.29 & {}[-1.44, 28.02] & 1.78 & 152 & .077 & NA\\
Dneg c $\times$ Order1 & -7.34 & {}[-15.44, 0.76] & -1.79 & 152 & .075 & NA\\
B c $\times$ Order1 & -0.04 & {}[-1.36, 1.28] & -0.06 & 152 & .951 & NA\\
A c $\times$ Order1 & -16.89 & {}[-36.55, 2.78] & -1.70 & 152 & .092 & NA\\
\bottomrule
\end{tabular}

\end{threeparttable}
\end{center}

\end{table}

\begin{table}[tbp]

\begin{center}
\begin{threeparttable}

\caption{\label{tab:unnamed-chunk-20}Model 1: Linear model predicting individual EC effects from $D$, $C$, $d_{pos}$, $d_{neg}$, $b$ and $a$.}

\begin{tabular}{lrrrrrr}
\toprule
Predictor & \multicolumn{1}{c}{$b$} & \multicolumn{1}{c}{95\% CI} & \multicolumn{1}{c}{$t$} & \multicolumn{1}{c}{$\mathit{df}$} & \multicolumn{1}{c}{$p$} & \multicolumn{1}{c}{VIF}\\
\midrule
Intercept & 4.63 & {}[4.36, 4.89] & 34.68 & 150 & < .001 & ---\\
$D$ & 0.29 & {}[-0.97, 1.54] & 0.45 & 150 & .655 & 5.36\\
$C$ & 2.61 & {}[0.18, 5.05] & 2.12 & 150 & .036 & 34.4\\
$d_{\mathrm{pos}}$ & -2.07 & {}[-4.55, 0.42] & -1.65 & 150 & .102 & 33.14\\
$d_{\mathrm{neg}}$ & -7.53 & {}[-22.25, 7.20] & -1.01 & 150 & .314 & 11.38\\
$b$ & 2.66 & {}[-4.33, 9.66] & 0.75 & 150 & .453 & 6.46\\
$a$ & 1.74 & {}[0.52, 2.96] & 2.82 & 150 & .006 & 2.72\\
A c & 3.72 & {}[-16.66, 24.11] & 0.36 & 150 & .719 & NA\\
Order1 & -0.14 & {}[-0.40, 0.12] & -1.05 & 150 & .293 & NA\\
D c $\times$ Order1 & 0.81 & {}[-0.45, 2.07] & 1.27 & 150 & .206 & NA\\
Cpos c $\times$ Order1 & 1.97 & {}[-0.46, 4.41] & 1.60 & 150 & .112 & NA\\
Cneg c $\times$ Order1 & -2.47 & {}[-4.96, 0.01] & -1.97 & 150 & .051 & NA\\
Dpos c $\times$ Order1 & -2.15 & {}[-16.87, 12.57] & -0.29 & 150 & .773 & NA\\
Dneg c $\times$ Order1 & -3.60 & {}[-10.60, 3.39] & -1.02 & 150 & .310 & NA\\
B c $\times$ Order1 & -0.13 & {}[-1.35, 1.09] & -0.21 & 150 & .834 & NA\\
A c $\times$ Order1 & 0.39 & {}[-19.99, 20.77] & 0.04 & 150 & .970 & NA\\
\bottomrule
\end{tabular}

\end{threeparttable}
\end{center}

\end{table}

\begin{table}[tbp]

\begin{center}
\begin{threeparttable}

\caption{\label{tab:unnamed-chunk-21}Model 1: Linear model predicting individual EC effects from $D$, $C$, $d_{pos}$, $d_{neg}$, $b$ and $a$.}

\begin{tabular}{lrrrrrr}
\toprule
Predictor & \multicolumn{1}{c}{$b$} & \multicolumn{1}{c}{95\% CI} & \multicolumn{1}{c}{$t$} & \multicolumn{1}{c}{$\mathit{df}$} & \multicolumn{1}{c}{$p$} & \multicolumn{1}{c}{VIF}\\
\midrule
Intercept & 0.81 & {}[0.51, 1.12] & 5.32 & 90 & < .001 & ---\\
$D$ & 3.07 & {}[1.49, 4.65] & 3.87 & 90 & < .001 & 2.97\\
$C$ & 1.36 & {}[0.04, 2.68] & 2.04 & 90 & .044 & 3.51\\
$d_{\mathrm{pos}}$ & -6.76 & {}[-21.04, 7.51] & -0.94 & 90 & .349 & 2.12\\
$d_{\mathrm{neg}}$ & 12.97 & {}[4.37, 21.57] & 3.00 & 90 & .004 & 2.94\\
$b$ & -0.48 & {}[-2.65, 1.70] & -0.43 & 90 & .665 & 1.89\\
\bottomrule
\end{tabular}

\end{threeparttable}
\end{center}

\end{table}

\begin{table}[tbp]

\begin{center}
\begin{threeparttable}

\caption{\label{tab:unnamed-chunk-22}Model 1: Linear model predicting individual EC effects from $D$, $C$, $d_{pos}$, $d_{neg}$, $b$ and $a$.}

\begin{tabular}{lrrrrrr}
\toprule
Predictor & \multicolumn{1}{c}{$b$} & \multicolumn{1}{c}{95\% CI} & \multicolumn{1}{c}{$t$} & \multicolumn{1}{c}{$\mathit{df}$} & \multicolumn{1}{c}{$p$} & \multicolumn{1}{c}{VIF}\\
\midrule
Intercept & 0.91 & {}[0.42, 1.41] & 3.68 & 63 & < .001 & ---\\
$D$ & 1.21 & {}[-1.09, 3.50] & 1.05 & 63 & .297 & 5.39\\
$C$ & 1.06 & {}[-0.99, 3.11] & 1.03 & 63 & .307 & 7.97\\
$d_{\mathrm{pos}}$ & 12.26 & {}[-8.47, 32.99] & 1.18 & 63 & .242 & 6.78\\
$d_{\mathrm{neg}}$ & 0.73 & {}[-11.54, 13.01] & 0.12 & 63 & .905 & 2.26\\
$b$ & -0.93 & {}[-2.35, 0.49] & -1.30 & 63 & .197 & 1.38\\
$a$ & -15.80 & {}[-37.00, 5.39] & -1.49 & 63 & .141 & 4.28\\
\bottomrule
\end{tabular}

\end{threeparttable}
\end{center}

\end{table}

\begin{table}[tbp]

\begin{center}
\begin{threeparttable}

\caption{\label{tab:unnamed-chunk-23}Model 1: Linear model predicting individual EC effects from $D$, $C$, $d_{pos}$, $d_{neg}$, $b$ and $a$.}

\begin{tabular}{lrrrrrr}
\toprule
Predictor & \multicolumn{1}{c}{$b$} & \multicolumn{1}{c}{95\% CI} & \multicolumn{1}{c}{$t$} & \multicolumn{1}{c}{$\mathit{df}$} & \multicolumn{1}{c}{$p$} & \multicolumn{1}{c}{VIF}\\
\midrule
Intercept & 0.91 & {}[0.42, 1.41] & 3.68 & 63 & < .001 & ---\\
$D$ & 1.21 & {}[-1.09, 3.50] & 1.05 & 63 & .297 & 5.39\\
$C$ & 1.06 & {}[-0.99, 3.11] & 1.03 & 63 & .307 & 7.97\\
$d_{\mathrm{pos}}$ & 12.26 & {}[-8.47, 32.99] & 1.18 & 63 & .242 & 6.78\\
$d_{\mathrm{neg}}$ & 0.73 & {}[-11.54, 13.01] & 0.12 & 63 & .905 & 2.26\\
$b$ & -0.93 & {}[-2.35, 0.49] & -1.30 & 63 & .197 & 1.38\\
$a$ & -15.80 & {}[-37.00, 5.39] & -1.49 & 63 & .141 & 4.28\\
\bottomrule
\end{tabular}

\end{threeparttable}
\end{center}

\end{table}

\begin{table}[tbp]

\begin{center}
\begin{threeparttable}

\caption{\label{tab:unnamed-chunk-24}Linear model predicting individual EC effects from $D$, $C$, $d$, $b$ and $a$.}

\begin{tabular}{lrrrrrr}
\toprule
Predictor & \multicolumn{1}{c}{$b$} & \multicolumn{1}{c}{95\% CI} & \multicolumn{1}{c}{$t$} & \multicolumn{1}{c}{$\mathit{df}$} & \multicolumn{1}{c}{$p$} & \multicolumn{1}{c}{VIF}\\
\midrule
Intercept & 0.72 & {}[0.47, 0.98] & 5.63 & 154 & < .001 & ---\\
$D$ & 2.06 & {}[0.81, 3.32] & 3.24 & 154 & .001 & 3.7\\
$C$ & 1.26 & {}[-0.19, 2.71] & 1.72 & 154 & .087 & 7.98\\
$d$ & 11.21 & {}[2.81, 19.60] & 2.64 & 154 & .009 & 1.74\\
$b$ & -0.45 & {}[-1.69, 0.78] & -0.72 & 154 & .470 & 1.94\\
$a$ & -9.05 & {}[-24.64, 6.54] & -1.15 & 154 & .253 & 6.19\\
Order1 & 0.06 & {}[-0.19, 0.32] & 0.48 & 154 & .631 & 4.34\\
D c $\times$ Order1 & -0.37 & {}[-1.63, 0.88] & -0.59 & 154 & .557 & 3.43\\
Cpn c $\times$ Order1 & -0.08 & {}[-1.53, 1.36] & -0.11 & 154 & .910 & 7.96\\
Dpn c $\times$ Order1 & -1.73 & {}[-10.12, 6.67] & -0.41 & 154 & .685 & 1.63\\
B c $\times$ Order1 & -0.62 & {}[-1.86, 0.61] & -0.99 & 154 & .321 & 1.56\\
A c $\times$ Order1 & -2.70 & {}[-18.30, 12.89] & -0.34 & 154 & .732 & 4.02\\
\bottomrule
\end{tabular}

\end{threeparttable}
\end{center}

\end{table}

\begin{table}[tbp]

\begin{center}
\begin{threeparttable}

\caption{\label{tab:unnamed-chunk-25}Linear model predicting individual EC effects from $D$, $C$, $d$ and $b$.}

\begin{tabular}{lrrrrrr}
\toprule
Predictor & \multicolumn{1}{c}{$b$} & \multicolumn{1}{c}{95\% CI} & \multicolumn{1}{c}{$t$} & \multicolumn{1}{c}{$\mathit{df}$} & \multicolumn{1}{c}{$p$} & \multicolumn{1}{c}{VIF}\\
\midrule
Intercept & 0.79 & {}[0.63, 0.94] & 10.17 & 156 & < .001 & ---\\
$D$ & 2.29 & {}[1.10, 3.49] & 3.79 & 156 & < .001 & 3.36\\
$C$ & 0.62 & {}[-0.37, 1.60] & 1.23 & 156 & .221 & 3.73\\
$d$ & 10.07 & {}[1.91, 18.23] & 2.44 & 156 & .016 & 1.65\\
$b$ & -0.54 & {}[-1.76, 0.69] & -0.86 & 156 & .390 & 1.92\\
Order1 & 0.19 & {}[0.04, 0.34] & 2.44 & 156 & .016 & 1.58\\
D c $\times$ Order1 & -0.17 & {}[-1.36, 1.03] & -0.27 & 156 & .784 & 3.12\\
Cpn c $\times$ Order1 & -0.35 & {}[-1.34, 0.64] & -0.70 & 156 & .484 & 3.73\\
Dpn c $\times$ Order1 & -2.13 & {}[-10.29, 6.03] & -0.51 & 156 & .607 & 1.55\\
B c $\times$ Order1 & -0.69 & {}[-1.92, 0.54] & -1.11 & 156 & .271 & 1.54\\
\bottomrule
\end{tabular}

\end{threeparttable}
\end{center}

\end{table}

\begin{table}[tbp]

\begin{center}
\begin{threeparttable}

\caption{\label{tab:unnamed-chunk-31}Model 2: Linear model predicting individual EC effects from $D$, $C$, $d_{pos}$ and $d_{neg}$ (including two-way interactions between $D$ and $C$, $d_{pos}$ or $d_{neg}$)}

\begin{tabular}{lrrrrrr}
\toprule
Predictor & \multicolumn{1}{c}{$b$} & \multicolumn{1}{c}{95\% CI} & \multicolumn{1}{c}{$t$} & \multicolumn{1}{c}{$\mathit{df}$} & \multicolumn{1}{c}{$p$} & \multicolumn{1}{c}{VIF}\\
\midrule
Intercept & 0.61 & {}[0.44, 0.77] & 7.23 & 158 & < .001 & ---\\
$D$ & 2.72 & {}[1.53, 3.90] & 4.53 & 158 & < .001 & 3.38\\
$C$ & 1.34 & {}[0.48, 2.20] & 3.07 & 158 & .003 & 2.89\\
$d_{\mathrm{pos}}$ & -5.69 & {}[-13.25, 1.87] & -1.49 & 158 & .139 & 2.14\\
$d_{\mathrm{neg}}$ & 7.13 & {}[3.08, 11.19] & 3.47 & 158 & < .001 & 1.55\\
$D$ $\times$ $C$ & 3.48 & {}[-1.36, 8.32] & 1.42 & 158 & .158 & 2.85\\
$D$ $\times$ $d_{\mathrm{pos}}$ & -9.73 & {}[-43.38, 23.91] & -0.57 & 158 & .569 & 1.84\\
$D$ $\times$ $d_{\mathrm{neg}}$ & -5.98 & {}[-29.17, 17.22] & -0.51 & 158 & .612 & 1.59\\
\bottomrule
\end{tabular}

\end{threeparttable}
\end{center}

\end{table}

\begin{verbatim}
## Start:  AIC=-75.89
## ec ~ a.c + b.c + D.c + Cpn.c + dpos.c + dneg.c + order
\end{verbatim}

\begin{verbatim}
## 
## Call:
## lm(formula = ec ~ a.c + b.c + D.c + Cpn.c + dpos.c + dneg.c + 
##     order, data = para_ratings)
## 
## Coefficients:
## (Intercept)          a.c          b.c          D.c        Cpn.c       dpos.c  
##     0.71378     -0.19242     -0.98025      2.90324      0.97193     -5.02756  
##      dneg.c       order1  
##    11.09771     -0.02931
\end{verbatim}

\hypertarget{baseline-corrected-cs-evaluations}{%
\subsubsection{Baseline-corrected CS evaluations}\label{baseline-corrected-cs-evaluations}}

\hypertarget{additional-analyses}{%
\subsection{Additional analyses}\label{additional-analyses}}

\hypertarget{general-discussion}{%
\section{General discussion}\label{general-discussion}}

\hypertarget{amazing-paragraph}{%
\subsection{Amazing paragraph}\label{amazing-paragraph}}

smart conclusion 1

\hypertarget{another-amazing-paragraph}{%
\subsection{Another amazing paragraph}\label{another-amazing-paragraph}}

smart conclusion 2

\hypertarget{appendix}{%
\section{Appendix}\label{appendix}}

\hypertarget{appendix-appendix}{%
\appendix}


\hypertarget{amazing-paragraph-1}{%
\subsection{Amazing paragraph}\label{amazing-paragraph-1}}

additional information on something amazing

\hypertarget{another-amazing-paragraph-1}{%
\subsection{Another amazing paragraph}\label{another-amazing-paragraph-1}}

more information on another amazing thing


\end{document}
