---
title             : "Memory specificity in evaluation conditioning: a 'Who said what' approach"
shorttitle        : "Memory specificity in EC"

author: 
  - name          : "Karoline Bading"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Schleichstraße 4, 72074 Tübingen (Germany)"
    email         : "karoline.bading@uni-tuebingen.de"
  - name          : "Jérémy Béna"
    affiliation   : "2"
    # role: # Contributorship roles (e.g., CRediT, https://credit.niso.org/)
    #   - "Conceptualization"
    #   - "Writing - Original Draft Preparation"
    #   - "Writing - Review & Editing"
  - name          : "Marius Barth"
    affiliation   : "3"
    # role:
    #   - "Writing - Review & Editing"
    #   - "Supervision"
  - name          : "Klaus Rothermund"
    affiliation   : "4"
    # role:
    #   - "Writing - Review & Editing"
    #   - "Supervision"
      
affiliation:
  - id            : "1"
    institution   : "University of Tübingen"
  - id            : "2"
    institution   : "Aix-Marseille University"
  - id            : "3"
    institution   : "University of Cologne"
  - id            : "4"
    institution   : "Friedrich Schiller University Jena"
    


abstract: |
  BLABLABLABLABLA

  <!-- https://tinyurl.com/ybremelq -->
  
  
authornote: |
  Karoline Bading, University of Tübingen,
  Jérémy Béna, Aix-Marseille University,
  Marius Barth, University of Cologne,
  Klaus Rothermund, University of Jena.
  Karoline Bading and Jérémy Béna share first authorship.
  
keywords          : "keywords"
wordcount         : "X"

bibliography      : ["r-references.bib", "`r methexp_bib()`"]
floatsintext      : yes
linenumbers       : no
draft             : no
mask              : no

figurelist        : no
tablelist         : no
footnotelist      : no

classoption       : man
output            : papaja::apa6_pdf
---

```{r setup, include = FALSE}
library(afex)
library(emmeans)
library(ggeffects)
library(papaja)
library(dplyr)
library(MPTinR)
library(TreeBUGS)

r_refs("r-references.bib")

project_root <- rprojroot::find_rstudio_root_file()

study_folder_pilot <- file.path(
  project_root
  , "pilot_data_analyses"
)

study_folder_main <- file.path(
  project_root
  , "Study 2"
)

study_folders <- list(
    wsw1 = file.path(project_root, "studies", "wsw1")
  , wsw2_main = file.path(project_root, "studies", "wsw2-main")
  , wsw3_main = file.path(project_root, "studies", "wsw3-main")
  , wsw3_p2   = file.path(project_root, "studies", "wsw3-p2")
)

source(file.path(project_root, "R", "apa_print_treebugs.R"))
source(file.path(project_root, "R", "mptinr_helper.R"))

knitr::opts_chunk$set(
  echo = FALSE
  , warning = FALSE
  , message = FALSE
  , cache = FALSE
  , fig.env = "figure*"
)
```

```{r analysis-preferences}
# Seed for random number generation
# set.seed(42)
# knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```

# Experiment 1 (Pilot)

```{r}
# from MB:
data_list <- readRDS(file.path(study_folders$wsw1, "data", "data.rds"))
#data_list$excluded_participants
```




## Methods
The experiment was not pre-registered.
The materials and data are publicly available at: https://osf.io/rqkvy/.
The study was run online.

### Participants

### Design
The experiment followed a 2 (US valence: positive vs. negative) within-subjects design.

### Materials

### Measures and procedures

#### Learning phase
#### Test phase
#### Control measures

### Data processing

## Results

```{r}
exp1_trait_model <- readRDS(file.path(study_folders$wsw1, "model-objects", "trait-mpt.rds"))
exp1_trait_model_8b <- readRDS(file.path(study_folders$wsw1, "model-objects", "trait-mpt-wsw-8b.rds"))
```

## Discussion

# Experiment 2

```{r}
# from MB:
data_list <- readRDS(file.path(study_folders$wsw2_main, "data", "data.rds"))
#data_list$excluded_participants

n_final <- sum(length(unique(data_list$rating$sid)))
n_conditions <- split(data_list$rating, data_list$rating$task_order) |>
  lapply(function(x) {paste0("$n = ", length(unique(x$sid)), "$")})
n_conditions <- setNames(n_conditions, papaja::sanitize_terms(tolower(names(n_conditions))))


# ----
dat <- readRDS(file.path(project_root, "Paper", "/data/data_wsw2.RDS"))
dat$url.srid <- as.factor(dat$url.srid)
n_total <- length(unique(dat$url.srid))
dat <- dat %>% filter(pay_attention != 0 & serious != 0) %>% droplevels() 
n_final <- length(unique(dat$url.srid))
socio = read.csv(file.path(project_root, "/Paper/data/sociodemo.csv"))
socio = socio %>% filter(Status != "RETURNED")



```

## Method
The experiment was pre-registered on the OSF.
The pre-registration, materials and data are publicly available at: https://osf.io/rqkvy/.
The study was run online.

### Participants
Participants were recruited through Prolific and received monetary compensation for their participation.
The sampling pool was restricted to English speakers with at least 100 previous submissions and an approval rating of at least 90%.
Prolific users who had participated in our previous evaluative conditioning studies were excluded from the sampling pool.
We recruited 172 participants (50$\%$ female; $M_{age} =$ `r mean(as.numeric(socio$Age))`; $SD_{age} =$ `r sd(as.numeric(socio$Age))`).
Based on pre-registered criteria, we excluded five participants who declared that they did not pay attention or that they did not take their responses seriously.
We excluded another participant whose data was unavailable due to an unknown technical error.
Taken together, this resulted in a final sample size of `r n_final` participants (`r n_conditions$rating_first` in the evaluation task first condition and `r n_conditions$memory_first` in the memory task first condition).

The number of recruited participants was based on a power analysis for an EC effect as small as Cohen's $d = 0.2$. 
The power analysis was conducted with the R package *pwr* (version 1.3-0; Champely, 2020).
The test of the EC effect was implemented as a one-tailed paired-samples *t*-test with $\alpha=.05$ (IV: US valence; DV: evaluative ratings).
We found that 156 participants were required to achieve a statistical power of $1-\beta = .8$ to detect a significant EC effect.
We also found that a sample size of $N = 156$ provided statistical power of $1-\beta = .8$ to detect correlations $r\mathrm{s} \geq |.22|$ (e.g., between parameter estimates and evaluative ratings).
To avoid a final sample smaller than $N = 156$ after applying the pre-registered exclusion criteria, we chose to recruit 172 participants (the required sample size increased by 10%).

### Design
The experiment followed a 2 (US valence: positive vs. negative) $\times$ 2 (measurement task order: evaluation task first vs. memory task first) mixed design.
The first factor varied within participants and the second factor varied between participants.

### Materials
The experiment was programmed in *lab.js* [@henninger_labjs_2022].

The CS pool comprised 54 nonwords made up of five to seven letters (e.g., *botsy*, *ikzunt*, *ampfong*).
The nonwords were taken from a previous EC study (Stahl & Bading, 2020).
For each participant, 24 nonwords were randomly selected to serve as CSs during the learning phase.
Another 24 nonwords were randomly selected to serve as distractor stimuli in the test phase.

As USs, we used 24 colored images animals (e.g., a cockroach), scenes (e.g., a rainbow) and objects (e.g., a knife).
The images were taken from the Open Affective Standardized Image Set (OASIS; Kurdi et al., 2017). Based on OASIS ratings (on a 7-point Likert scale), 12 images were positive ($M_{valence} = 5.88$; $SD_{valence}$ = 0.24; $M_{arousal} = 4.10$; $SD_{arousal} = 0.50$) were therefore used as positive USs, while 12 were negative ($M_{valence} = 2.05$; $SD_{valence} = 0.32$; $M_{arousal} = 4.27$; $SD_{arousal} = 0.52$) and were thus used as negative USs. Positive and negative USs differed with regard valence, Welch’s $t(20.23) = 33.36, p < .001$, but not with regard to arousal, Welch’s $t(21.96) = 0.82, p = .419$. 
For each participant, the 24 USs were combined one-to-one with the 24 CSs (via random assignment).

### Measures and procedures
We used JATOS [@lange_just_2015] to run the study online.
All verbal materials were presented in English.
The task instructions can be found in the pre-registration (see OSF repository).

#### Learning phase
Participants were told that they would see pairs of nonwords and images and were instructed to pay close attention to each pair.
The learning phase consisted of 72 trials.
The trials were separated by blank screens presented for 1,000 ms.
On each trial, a nonword (CS, center-left position) was presented together with a valenced image (US, center-right position).
CS and US appeared at the same time and remained on screen for 1,000 ms.
For each participant, trial order was randomized in sets of 24 trials.
In each set (three in total), each of the 24 CS-US pairs was presented once.

#### Test phase
After the learning phase, participants entered the test phase. In the test phase, participants performed two measurement tasks: an evaluation task and a memory task. Participants were randomly assigned to one of the two measurement task order conditions. In the "evaluation task first" condition, participants performed the evaluation task and then the memory task. The task order was reversed in the "memory task first" condition. The wording of the task instructions differed slightly between task order conditions. 

##### Evaluation task
In the evaluation task, the 24 CSs and the 24 distractor stimuli were displayed individually without time limit. 
Participants rated how positive or negative they found each nonword on a 8-point Likert scale ranging from "very negative" (1) to "very positive" (8).
The 48 trials were separated by blank screens presented for 500 ms.
Trial order was randomized for each participant anew.

##### Memory task
In the memory task, the 24 CSs and the 24 distractor stimuli were displayed individually without time limit.
The 48 trials were separated by blank screens presented for 500 ms.
Trial order was randomized for each participant anew.

Each trial began with with the recognition memory task: participants were asked whether the nonword had been part of the nonword-image pairs presented in the learning phase.
To indicate their response, participants were presented with two buttons labeled "Yes (old)" and "No (new)".
If participants responded "No (new)", they proceeded to the next recognition memory trial.
If participants responded "Yes (old)", they proceeded to the associative memory task (in which they were asked to identify the previously paired US).
In this task, the nonword was presented together with eight images (all of which had been shown as USs during the learning phase).
The eight images were displayed in two rows of four images (with random assignment of images to positions).
For CSs that were correctly recognized as "old", the correct US was presented together with seven randomly selected distractors (3 images of the same valence as the correct US; 4 images of the opposite valence). 
For distractor stimuli incorrectly classified as "old", eight randomly selected images (4 $\times$ positive, 4 $\times$ negative) were presented.
Participants were instructed to guess the correct option if they could not remember the previously paired US.

#### Control measures and debriefing
After the test phase, participants were asked whether they paid attention to the nonwords and images presented throughout the experiment.
The response options ("Yes" vs. "No") were presented as two buttons.
Subsequently, participants were asked whether they took the requested responses seriously.
The response options ("I have taken the requested responses seriously" vs. "I have just clicked through, please discard my data") were again presented as two buttons.
Subsequently, participants were given the chance to comment on the study.
Finally, participants were debriefed about the purpose of the study and then redirected to Prolific.

### Data processing and statistical analysis

## Results

```{r}
exp2_trait_model <- readRDS(file.path(study_folders$wsw2_main, "model-objects", "trait-mpt.rds"))
exp2_trait_model_8b <- readRDS(file.path(study_folders$wsw2_main, "model-objects", "trait-mpt-wsw-8b.rds"))
```


```{r}
ratings_and_parameters <- merge(data_list$rating_wide, get_theta(exp2_trait_model))

rating_and_parameters_long <- merge(data_list$rating, get_theta(exp2_trait_model_8b)) |>
  within({
    d <- ifelse(us_valence == "positive", d_positive, d_negative)
    C <- ifelse(us_valence == "positive", C_positive, C_negative)
  })

```







## Discussion

# Experiment 3

```{r}
# from MB:
data_list <- readRDS(file.path(study_folders$wsw3_main, "data", "data.rds"))
#data_list$excluded_participants                       # Participant IDs
lapply(data_list$excluded_participants, FUN = length) # How many?
```


## Method
The experiment was pre-registered on the OSF.
The pre-registration, materials and data are publicly available at: https://osf.io/rqkvy/.
The study was run online.

### Participants

```{r}

demographics <- read.csv(file.path(study_folders$wsw3_main, "data-raw", "demographics.csv")) |>
  subset(Status == "APPROVED") |>
  within({
    Age <- as.integer(Age)
    Sex <- factor(Sex, levels = c("Female", "Male"))
  })

n_sex <- table(demographics$Sex)
prop_sex <- as.list(proportions(n_sex)) |>
  lapply(function(x) {
    paste0("$",apa_num(x * 100), "\\%$")
  })

age <- with(demographics, {
  paste0(
    "$M_\\mathrm{age} = "
    , apa_num(mean(Age))
    , "$, $\\mathit{SD}_\\mathrm{age} = "
    , apa_num(sd(Age))
    , "$"
  )
})

n_conditions <- split(data_list$rating, data_list$rating$task_focus) |>
  lapply(function(x) {paste0("$n = ", length(unique(x$sid)), "$")})
n_conditions <- setNames(n_conditions, papaja::sanitize_terms(tolower(names(n_conditions))))



```


Participants were recruited through Prolific and received monetary compensation for their participation.
We collected a quota sample with approximately equal shares of male and female participants.
The sampling pool was restricted to Prolific users (1) whose first language is English, (2) who live in the USA or in the United Kingdom, and (3) who have at least 20 previous submissions and a Prolific approval rate of at least 90%.
Prolific users who participated in previous pretests and experiments (conducted by the members of the current team of authors) using the same materials were excluded from the sampling pool.

We recruited 142 participants (`r prop_sex$Female` female; `r age`).
As pre-registered,
we excluded `r length(unique(unlist(data_list$excluded_participants)))` participants
who failed at least one control measure (by selecting at least one physical activity, by reporting a lack of attention or by responding with "I have just clicked through, please discard my data").
Taken together, this resulted in a final sample size of `r sum(n_sex)` participants (`r n_conditions$valence` in the valence focus condition and `r n_conditions$age` in the age focus condition).

The number of recruited participants was based on a pre-registered sampling plan (see OSF repository).
We pre-registered a minimum sample size (per learning task focus condition), a maximum sample size (across learning task focus conditions), and two stopping criteria (determining the [dis-]continuation of data collection within the pre-registered sample size range).
The minimum sample size ($N=52$ participants per learning task focus condition) was based on a power analyses for the two-way interaction between US valence and learning task focus.
In this power analysis, we targeted a test power of $1-\beta=.9$ and used an $\alpha$-level of $.1$ to implement a one-tailed test of the two-way interaction (reflecting our directional prediction about the interaction pattern).
The effect size of the US valence $\times$ Task focus interaction was set to $\eta^2_{p}\approx.079$ (corresponding, approximately, to one half of the effect size obtained in a pilot study).
In a first round of data collection, we recruited participants until the minimum sample size (after applying exclusion criteria) was reached.
Based on the available data, we then fitted the pre-registered MPT model (see below) and calculated Bayes factors comparing a nested version of the model with $d_\textrm{valence-focus}=d_\textrm{age-focus}$ to the baseline model with free $d_\textrm{valence-focus}$ and $d_\textrm{age-focus}$ (for details, see section "Data processing and statistical analyses").
The data collection was discontinued at this point because the first stopping criteria was met: the Bayes factor in favor of the baseline model exceeded 10 (i.e., we found strong evidence for the presence of a learning task focus effect on the $d$ parameter).

### Design
The experiment followed a 2 (US valence: positive vs. negative) $\times$ 2 (US age: young vs. old) $\times$ 2 (learning task focus: valence focus vs. age focus) mixed design.
The first factor varied within participants and the second factor varied between participants.

### Materials
The experiment was programmed with *lab.js* [@henninger_labjs_2022] and exported to an HTTPS-protected website with JATOS [@lange_just_2015].

The CS pool comprised 48 colored images of middle-aged human faces with neutral expressions (24 female faces, 24 male faces).
The images were taken from the FACES database (Ebner, Riediger, & Lindenberger, 2010) and optimized with an AI image optimization tool.

The US pool comprised 24 adjectives describing human traits, with six adjectives in each US valence $\times$ US age condition.
Based on a pilot study, we selected six adjectives describing traits that are positive and more typical for younger (than for older) people (*energetic*, *flexible*, *lively*, *open-minded*, *optimistic*, *strong* ), six adjectives describing traits that are positive and more typical for older (than for younger) people (*calm*, *dignified*, *nurturing*, *patient*, *realistic*, *wise*), six adjectives describing traits that are negative and more typical for younger (than for older) people (*careless*, *impulsive*, *naive*, *selfish*, *spoilt*, *self-absorbed*), and six adjectives describing traits that are negative and more typical for older (than for younger) people (*demented*, *feeble*, *frail*, *rigid*, *stubborn*, *self-weak*). 

For each participant, 12 randomly selected face images (50% female) served as positively paired CSs (i.e., they were paired with a positive US during the learning phase), 12 randomly selected face images (50% female) served as negatively paired CSs, and the remaining 24 face images served as distractor stimuli in the test phase.

For each participant, all 24 adjectives served as USs during the learning phase. The 24 adjectives were randomly assigned to the 24 CSs.
Six CSs (50% female) were paired with positive and "younger" USs, six CSs (50% female) were paired with positive and "older" USs, six CSs (50% female) were paired with negative and "younger" USs, and six CSs (50%) were paired with negative and "older" USs.

### Measures and procedures
All verbal materials were presented in English.
After providing informed consent and being asked to focus on the study,
participants were thanked for their participation and asked to carefully read all instructions and perform the tasks.
Subsequently, participants were presented with the instructions for the learning phase.

#### Learning phase
All participants read the following instructions:
"In the first part of the experiment you will be presented with photographs of faces (called 'faces' below) shown together with adjectives that denote human traits (called 'traits' below).
Each face will be paired with a single trait.
For each face-trait pair, the trait will be presented first. 
After a brief delay, the face will appear underneath.
Please pay close attention to all traits and faces.
Each face-trait pair will be presented for a limited time.
Your task will be to form an impression of each face-trait pair."

Next, depending on the learning task focus condition (valence focus or age focus), participants read:
"Specifically, you will have to indicate whether you think each face-trait pair is rather 'negative' ['typically old'] or rather 'positive' ['typically young'].
Press the spacebar to continue with the instructions."

The ordering of the two category labels in the presented sentence was randomly determined for each participant anew (valence focus condition: "positive first" vs. "negative first"; age focus condition: "typically old first" vs. "typically young first").
Note that the key assignment in the learning phase matched the ordering of the category labels in the instructions (e.g., when the "positive" label was mentioned first [i.e., further to the left in the sentence], the "positive" response was assigned to the left-hand key [A]).

The instructions continued as follows: 
"Next, you will be presented with the face-trait pairs.
Again, your task is to form an impression of each face-trait pair. You need to carefully look at both the faces and traits being presented.
Please indicate whether you think each pair is rather 'negative' ['typically old'] or rather 'positive' ['typically old'].
If you think the pair is rather 'negative' ['typically old'], press 'A' on your keyboard.
If you think the pair is rather 'positive' [typically young'], press 'L' on your keyboard. 
Although the presentation time is limited, 
please try your best to provide a response on each face-trait pair.
This part of the experiment will take about 8 minutes.
When you are ready, press the spacebar to start the task.
(This may take a few seconds.)"

Subsequently, participants worked through the learning task, consisting of 72 trials.
Each trial started with a US presented alone in green lower-case letters against a black background at the top of the screen. After 1000 ms, the CS appeared right below the US. 
The CS-US pair remained on screen for 4000 ms.
Participants had to respond within 3000 ms after the onset of the US (by pressing the "A" or "L" key).
If participants responded in time, three hyphens appeared below the CS-US pair right after participants had entered a response (to indicate that the response was recorded).
If participants did not respond in time (i.e., within the 3000 ms), the text "no response" appeared in red below the CS-US pair for 1000 ms.
The CS-US pair then disappeared and the message "No response. Press the spacebar to continue." was displayed (in red) at the bottom of the screen (without time limit).
The trials were separated by empty screens presented for 2500 ms.
For each participant, trial order was randomized in sets of 24 trials.
In each set (three in total), each of the 24 CS-US pairs was presented once.

After the learning phase, the following text was displayed: "The first part of the experiment is now finished! You have now seen all face-trait pairs and may continue with the second part of the experiment. 
Press the spacebar to continue."

#### Test phase
After the learning phase, participants entered the test phase. 
In the test phase, participants performed two measurement tasks: an evaluation task followed by a memory task. 
The order of the two tasks (evaluation task first) was the same for all participants.
The task instructions can be found in the pre-registration (see OSF repository).

##### Evaluation task
In the evaluation task, the 24 CSs and the 24 distractor stimuli were displayed individually without time limit. 
Participants rated how positive or negative they found each face on a 8-point Likert scale ranging from "very negative" (1) to "very positive" (8).
The 48 trials were separated by blank screens presented for 500 ms.
Trial order was randomized for each participant anew.

##### Memory task
In the memory task, the 24 CSs and the 24 distractor stimuli were displayed individually without time limit.
The 48 trials were separated by blank screens presented for 500 ms.
Trial order was randomized for each participant anew.

Each trial began with with the recognition memory task: participants were asked whether the face had been shown as part of the face-image pairs presented in the learning phase.
To indicate their response, participants were presented with two buttons labeled "Shown" and "Not shown".
(Note that we used these response labels [instead of "old" and "new"] to avoid confusion with the response labels in the age focus task.)
If participants responded "Not shown", they proceeded to the next recognition memory trial.
If participants responded "Shown", they proceeded to the associative memory task (in which they were asked to identify the previously paired US).
In this task, the face image was presented together with 16 adjectives (four adjectives per US valence $\times$ US age condition).
Note that all presented adjectives had been shown as USs during the learning phase.
The 16 adjectives were displayed as buttons organized in three rows (with six buttons in the upper two rows and four buttons in the bottom row).
For truly "shown" faces, the correct US was presented on a randomly selected button, while the remaining buttons were filled with 15 randomly selected USs that have been paired with other CSs.
For new faces (erroneously classified as "shown"), the buttons will be filled with 16 randomly selected USs. 
After clicking on one of the 16 USs, participants were presented with a blank screen (500 ms) followed by the next trial (i.e., they were presented with a screen showing another face, the recognition task question, and the two response options).

#### Control measures and debriefing
After the test phase, participants were presented with a total of three control measures (all of which were used were as exclusion criteria).
First, participants were presented with a screen showing four long sentences in a single paragraph.
The first three sentences referred to attitude research and through length and writing style was meant to discourage participants from reading the whole text. 
In the very last sentence of the text, participants were instructed to ignore the upcoming question about their exercise habits (in order to demonstrate that they had read the entire passage). 
On the next screen, participants were presented with a list of seven physical activities and were asked to indicate which of these activities they perform regularly (by ticking a small box next to the respective activity). 
After having ticked all relevant boxes (or none at all), participants proceeded to the next screen by clicking on the "Continue" button displayed at the bottom of the screen.
Subsequently, participants were asked whether they paid attention to the nonwords and images presented throughout the experiment.
The response options ("Yes" vs. "No") were presented as two buttons.
Next, participants were asked whether they took the requested responses seriously [based on @aust_seriousness_2013].
The response options ("I have taken the requested responses seriously" vs. "I have just clicked through, please discard my data") were again presented as two buttons.
Afterwards, participants were given the chance to comment on the study.
Finally, participants were debriefed about the purpose of the study and then redirected to Prolific.

### Data processing and statistical analysis

## Results

```{r}
exp3_trait_model <- readRDS(file.path(study_folders$wsw3_main, "model-objects", "trait-mpt.rds"))
exp3_trait_model_8b <- readRDS(file.path(study_folders$wsw3_main, "model-objects", "trait-mpt-wsw-8b.rds"))
```


## Discussion 

# General discussion

# References

::: {#refs custom-style="Bibliography"}
:::


# (APPENDIX) Appendix {-}

```{r child = file.path(project_root, "Paper/appendix.rmd"), eval = TRUE}
```



