---
title: "Who said what EC: A basis for analyses"
author: "Jérémy Béna"
output:
  html_document:
    toc: true
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, comment = NA)
```

# Load packages and read the data

```{r set}
#Load (or install and load) packages
require(pacman)
p_load('tidyverse', 'psych', 'effectsize', 'afex', 'bfrr', 'papaja', 'kableExtra', 'MPTinR', 'TreeBUGS') 
set_sum_contrasts()

#read the dataset we created in a previous R script
dat = readRDS("data_wsw_final_pilot.RDS") 

#some factors are integer or character variables in the dataset; make them factors
dat$url.srid = as.factor(dat$url.srid)
dat$cs_category = as.factor(dat$cs_category)
dat$us_valence = as.factor(dat$us_valence)
dat$reco_resp = as.factor(dat$reco_resp)
```

# Exclude participants

```{r exclude}
#exclude participants declaring they did not take their responses seriously
##or did not pay attention
dat = dat %>% filter(pay_attention != 0 & serious != 0) %>% droplevels() #drop level to remove excluded ppts
length(unique(dat$url.srid)) # N of participants after exclusion
```

# Code responses in the recognition/CS-US pairing memory tasks

```{r recode}
#create a new factor to distinguish between old and new CSs 
dat$cs_exposure = ifelse(dat$us_valence == "dist", "new", "old")
table(dat$cs_exposure, dat$us_valence)

#indicate whether the recognition decision is correct (hit and cr) or not (fa and miss)
dat = dat %>%
  mutate(reco_accuracy = ifelse((cs_exposure=="old" & reco_resp == "old"), "hit"
                                ,ifelse((cs_exposure=="old" & reco_resp == "new"), "miss"
                                ,ifelse((cs_exposure=="new" & reco_resp == "old"), "fa", "cr"))
                                ))

#indicate whether source memory is correct regarding valence (positive or negative)
dat$correct_us_source = NA
dat$source_mem_resp = NA

for(i in 1:length(dat$url.srid)){
  dat$correct_us_source[i] = dat$uss[[i]][dat$idtarg[i]+1]
  dat$source_mem_resp[i] = dat$uss[[i]][as.numeric(substr(dat$source_mem, 3, 3))[i]]
}

#calculate whether us valence and us identity memory are correct or not
dat = dat %>%
  mutate(val_us_accuracy = ifelse(substr(source_mem_resp, 0, 1) == substr(correct_us_source, 0, 1), "val_correct", "val_incorrect")
        ,id_us_accuracy = ifelse(source_mem_resp == correct_us_source, "id_correct", "id_incorrect")
         )

table(dat$val_us_accuracy)
table(dat$id_us_accuracy)

#replace NA with "no_resp" when no response was provided in the source memory task, 
##whether this is correct (for old css) or not (for new css)
dat = dat %>% mutate(val_us_accuracy = replace_na(val_us_accuracy, "no_resp")
                     ,id_us_accuracy = replace_na(id_us_accuracy, "no_resp"))
```

# Evaluative ratings

```{r eval_change}
####
#EVALUATIVE CONDITIONING
####

#compute mean evaluative change scores for each participant as a function of US Valence 
dat_ev = dat %>%
  group_by(url.srid, us_valence) %>%
  summarize(eval_rating = mean(as.numeric(cs_rating)))

knitr::kable(dat_ev, format = "html")

#check data distribution
# plot(density(dat_ev$eval_rating[dat_ev$us_valence=="positive"]))
# plot(density(dat_ev$eval_rating[dat_ev$us_valence=="dist"]))
# plot(density(dat_ev$eval_rating[dat_ev$us_valence=="negative"]))
```

```{r eval_ratings}
mod1 = aov_ez(dat_ev
              ,id = "url.srid"
              ,dv = "eval_rating"
              ,within = "us_valence"
)

mod1_print = apa_print(mod1)

apa_table(
  mod1_print$table
  ,caption = "Repeated-measures ANOVA: Ratings as a function of US"
)

# Descriptive statistics: evaluative change scores as a function of US Valence
knitr::kable(describeBy(dat_ev$eval_rating, dat_ev$us_valence, mat = TRUE), digits = 2)

```

```{r plot_ratings, fig.cap="Evaluative ratings as a function of US Valence. Dots are the individual observations, and error bars are the 95% Confidence Intervals. *Note:* TBS = Two-buttons-sets procedure; VMA = Valence Memory Attribution task; 3ACE = Three-attribution, continuous evaluative ratings task."}
dat_ev$`US Valence` = dat_ev$us_valence

#visualize the data
apa_beeplot(data=dat_ev, id="url.srid", dv="eval_rating", factors=c("US Valence"), use = "all.obs", ylim=c(0,11),
            xlab = "US"
            ,ylab = "Mean evaluative ratings")
```
# Recognition memory

```{r recognition}
####
#RECOGNITION MEMORY
####

#compute recognition memory performance by computing freq("old"|old) (hits) and freq("old"|new) (fa)
dat = dat %>% mutate(reco_resp_bin = ifelse(reco_resp=="old", 1, 0))

dat_reco_agg = dat %>%
  group_by(url.srid, cs_exposure) %>%
  summarise(prop_old = mean(reco_resp_bin))

knitr::kable(dat_reco_agg, format = "html")

dat_reco_wide = dat_reco_agg %>% pivot_wider(names_from = "cs_exposure"
                                                 ,values_from = "prop_old")

dat_reco_wide$reco_corrected = dat_reco_wide$old - dat_reco_wide$new

describeBy(dat_reco_agg$prop_old, dat_reco_agg$cs_exposure)
describe(dat_reco_wide$reco_corrected)

#by us valence

dat_reco_agg_val = dat %>%
  group_by(url.srid, us_valence) %>%
  summarise(prop_old = mean(reco_resp_bin))

knitr::kable(dat_reco_agg_val, format = "html")

dat_reco_wide_val = dat_reco_agg_val %>% pivot_wider(names_from = "us_valence"
                                                 ,values_from = "prop_old")

dat_reco_wide_val$reco_corrected_pos = dat_reco_wide_val$positive - dat_reco_wide_val$dist
dat_reco_wide_val$reco_corrected_neg = dat_reco_wide_val$negative - dat_reco_wide_val$dist

describeBy(dat_reco_agg_val$prop_old, dat_reco_agg_val$us_valence)
describe(dat_reco_wide_val$reco_corrected_pos)
describe(dat_reco_wide_val$reco_corrected_neg)
```

# CS-US pairing memory

```{r source}
#Valence 

dat = dat %>% mutate(val_us_accuracy_bin = ifelse(val_us_accuracy=="val_correct", 1, 0))

dat_source_mem = dat %>% filter(us_valence != "dist" & reco_accuracy == "hit") %>%
  group_by(url.srid, us_valence) %>%
  summarise(prop_correct_source = mean(val_us_accuracy_bin))

knitr::kable(dat_source_mem, format = "html")

dat_source_mem_wide = dat_source_mem %>% pivot_wider(names_from = "us_valence"
                                                 ,values_from = "prop_correct_source")

dat_reco_agg_val_old = dat_reco_agg_val %>% filter(us_valence != "dist")
dat_reco_source = full_join(dat_reco_agg_val_old, dat_source_mem,
                               by = c("url.srid"="url.srid", "us_valence"="us_valence"))

describeBy(dat_reco_source$prop_correct_source, dat_reco_source$us_valence)

#Identity
dat = dat %>% mutate(id_us_accuracy_bin = ifelse(id_us_accuracy=="id_correct", 1, 0))

dat_id_mem = dat %>% filter(us_valence != "dist" & reco_accuracy == "hit") %>%
  group_by(url.srid, us_valence) %>%
  summarise(prop_correct_id = mean(id_us_accuracy_bin))

knitr::kable(dat_id_mem, format = "html")

dat_id_mem_wide = dat_id_mem %>% pivot_wider(names_from = "us_valence"
                                                 ,values_from = "prop_correct_id")

dat_mem = full_join(dat_reco_source, dat_id_mem,
                               by = c("url.srid"="url.srid", "us_valence"="us_valence"))

describeBy(dat_mem$prop_correct_id, dat_mem$us_valence)

knitr::kable(dat_mem, format = "html")

```

# Response frequencies + MPT model

```{r}
#compute response frequencies for MPT analyses

#First, remove NA in source memory responses and in the column storing the correct us
dat = dat %>% mutate(correct_us_source = replace_na(correct_us_source, "zz")
                     ,source_mem_resp = replace_na(source_mem_resp, "zz"))

##Create three datasets, one for each tree; them, we will merge them

##Tree: US+ and select only relevant columns
dat_pos = dat %>% filter(us_valence == "positive") %>% select(url.srid, cs, us_valence, correct_us_source, source_mem_resp)

#we compute responses as follows:
##if response == "zz", this means ppts provided a "new" response -- this is a "PosUSnew" as we are in the US+ tree
##then, if US identity response correct, response is "PosUSposcor"
##last, if US valence (in the absence of correct US identity response) is correct, "PosUSposincor" if valence is correct; else, "PosUSnegincor"
dat_pos = dat_pos %>% mutate(resp_mpt = ifelse(source_mem_resp == "zz"
                                               ,"PosUSnew"
                                               ,ifelse(source_mem_resp == correct_us_source
                                                       ,"PosUSposcor"
                                                       ,ifelse(substr(source_mem_resp, 0, 1)==substr(correct_us_source, 0, 1)
                                                              , "PosUSposincor"
                                                              , "PosUSnegincor"
                                                       )
                                               )
)
)

# /!\/!\/!\
# #ONLY run this code for TESTS
# we dont have "posUSposincor" in the test data, so I fake one "PosUSposincor" response
# a = which(dat_pos$resp_mpt=="PosUSposcor")
# dat_pos$resp_mpt[a[2]] = "PosUSposincor"
# //!\/!\

##Tree: US- and select only relevant columns
dat_neg = dat %>% filter(us_valence == "negative") %>% select(url.srid, cs, us_valence, correct_us_source, source_mem_resp)

#we compute responses as follows:
##if response == "zz", this means ppts provided a "new" response -- this is a "NegUSnew" as we are in the US- tree
##then, if US identity response correct, response is "NegUSnegcor"
##last, if US valence (in the absence of correct US identity response) is correct, "NegUSnegincor" if valence is correct; else, "NegUSposincor"
dat_neg = dat_neg %>% mutate(resp_mpt = ifelse(source_mem_resp == "zz"
                                               ,"NegUSnew"
                                               ,ifelse(source_mem_resp == correct_us_source
                                                       ,"NegUSnegcor"
                                                       ,ifelse(substr(source_mem_resp, 0, 1)==substr(correct_us_source, 0, 1)
                                                              , "NegUSnegincor"
                                                              , "NegUSposincor"
                                                       )
                                               )
)
)

#Tree: New and select only relevant columns
dat_new = dat %>% filter(us_valence == "dist") %>% select(url.srid, cs, us_valence, correct_us_source, source_mem_resp)

#we compute responses as follows:
##if response == "zz", this means ppts provided a "new" response -- this is a "Newnew" as we are in the New CS tree
##then, US memory responses are necessarily incorrect as no US was displayed
##if the selected US is positive, response is "Newposincor"
##if the selected US is negative, response is "Newnegincor"
dat_new = dat_new %>% mutate(resp_mpt = ifelse(source_mem_resp == "zz"
                                               ,"Newnew"
                                               ,ifelse(substr(source_mem_resp, 0, 1)=="p"
                                                              , "Newposincor"
                                                              , "Newnegincor")
)
)

#Merge datasets so that all responses are available into a single dataframe
##proceed in two stets: CS-US+ and CS-US- trees
dat_mpt.1 = full_join(dat_pos, dat_neg
                    ,by = c("url.srid"="url.srid", "cs"="cs", "us_valence"="us_valence", "correct_us_source"="correct_us_source","source_mem_resp"="source_mem_resp", "resp_mpt"="resp_mpt"))

#add new CS tree
dat_mpt = full_join(dat_mpt.1, dat_new
                    ,by = c("url.srid"="url.srid", "cs"="cs", "us_valence"="us_valence", "correct_us_source"="correct_us_source","source_mem_resp"="source_mem_resp", "resp_mpt"="resp_mpt"))
```

```{r}
# #participants frequencies for each response type, even if 0 responses for a given participant
# dat_mpt_freq = dat_mpt %>% #in dat_mpt
#   group_by(url.srid, resp_mpt, .drop=FALSE) %>% #group observations by participant (url.srid) and resp_mpt (already capturing the tree)
#   tally %>% 
#   spread(resp_mpt, n, fill=0) #use a "wide" format
# 
# dat_mpt_freq_fit = dat_mpt_freq %>% ungroup() %>% select(-url.srid) 
# 
# #aggregated level if needed
# dat_mpt_freq_agg = dat_mpt %>% #in dat_mpt
#   group_by(resp_mpt, .drop=FALSE) %>% #group observations by resp_mpt (already capturing the tree)
#   tally
```

```{r}

tmp <- table(dat_mpt$url.srid, dat_mpt$resp_mpt)
mpt_data <- data.frame(
  NegUSnegcor = tmp[, "NegUSnegcor"]
)
for (i in colnames(tmp)) {
  mpt_data[[i]] <- tmp[, i]
}

```

```{r}
#we'll use this model
MPTinR::check.mpt("KW_wsw_model.eqn")

if(file.exists("mod_mpt_KB.rds")) {
  mod_mpt_KB <- readRDS("mod_mpt_KB.rds")
} else {

  mod_mpt_KB = traitMPT(
  eqnfile = "KW_wsw_model.eqn"
  , data = mpt_data
  , n.iter   = 4e4
  , n.adapt  =  2e4
  , n.burnin = 2e4
  , n.thin   = 4e1
  , n.chains = 4
  , restrictions = list("Dn=Dpos=Dneg","G=0.25")
  , ppp = 5e3
  )
  saveRDS(mod_mpt_KB, file = "mod_mpt_KB.rds")
}

#Fit the model and estimate parameters

summary(mod_mpt_KB)

TreeBUGS::plotFit(mod_mpt_KB)
TreeBUGS::plotFreq(mod_mpt_KB)
TreeBUGS::plotParam(mod_mpt_KB)

mod_mpt_KB_ppp = PPP(mod_mpt_KB, M = 5e3)
mod_mpt_KB_ppp

#MPT on aggregated frequencies
# mod_agg = fit.mpt(data = dat_mpt_freq_agg$n
#         ,model.filename = "KW_wsw_model.eqn"
#         ,restrictions.filename = list("Dn=Dpos=Dneg","G=0.25")
#         )
# mod_agg
```

# Correlations between MPT parameters and CS ratings


```{r}

individual_parameters <- as.data.frame(getParam(mod_mpt_KB, parameter = "theta"))
parameter_names <- colnames(individual_parameters)
individual_parameters$url.srid <- rownames(individual_parameters)
saveRDS(individual_parameters, file = "individual-parameters-KB.rds")


# individual_parameters <- as.data.frame(getParam(mod_mpt, parameter = "theta"))
# individual_parameters$id <- 1:nrow(individual_parameters)
agg_data <- aggregate(eval_rating ~ us_valence + url.srid, data = dat_ev, FUN = mean)
library(reshape2)
agg_data_d <- dcast(agg_data, value.var = "eval_rating", url.srid ~ us_valence)
# agg_data_d$id <- 1:nrow(agg_data_d)
# 
para_ratings <- merge(agg_data_d, individual_parameters, by = "url.srid")
# 
# #para_ratings <- subset(para_ratings, url.srid %in% c("9860","9862","9864"))

# regression 1

para_ratings$ec <- para_ratings$positive-para_ratings$negative
contrasts(data$us_valence) <- "contr.sum"                   # = effects coding (i.e. sum-to-zero contrasts)
cntr <- center <- function(x) { x - mean(x, na.rm = TRUE) } # = function for centering
model <- lm(
  formula = ec ~ (cntr(a) + cntr(b) + cntr(Dn) + cntr(Cpos) + cntr(Cneg) + cntr(dpos) + cntr(dneg))
  , data = para_ratings
)
summary(model)
ggpredict(model, terms = ~ dpos + dneg) |>
  plot(rawdata = TRUE)
ggpredict(model, terms = ~ dneg + dpos) |>
  plot(rawdata = TRUE)
ggpredict(model, terms = ~ Cpos + Cneg) |>
  plot(rawdata = TRUE)
ggpredict(model, terms = ~ Cneg + Cpos) |>
  plot(rawdata = TRUE)
```

```{r}
# regression 2

id <- rep(1:length(para_ratings$url.srid),each = 2)
us_valence <- rep(c("positive","negative"),7)

regression_data <- data.frame(id = id
                              , us_valence = us_valence)

regression_data$order <- NA

regression_data$rating <- NA
regression_data$a <- NA
regression_data$b <- NA
regression_data$D <- NA
regression_data$Cpos <- NA
regression_data$Cneg <- NA
regression_data$dpos <- NA
regression_data$dneg <- NA

for(i in 1:nrow(regression_data)){
  tmp_id <- regression_data$id[i]
    regression_data$rating[i] <- para_ratings$positive[tmp_id]
    regression_data$a[i] <- para_ratings$a[tmp_id]
    regression_data$b[i] <- para_ratings$b[tmp_id]
    regression_data$D[i] <- para_ratings$Dn[tmp_id]
    regression_data$Cpos[i] <- para_ratings$Cpos[tmp_id]
    regression_data$Cneg[i] <- para_ratings$Cneg[tmp_id]
    regression_data$dpos[i] <- para_ratings$dpos[tmp_id]
    regression_data$dneg[i] <- para_ratings$dneg[tmp_id]
}

data <- regression_data
data$us_valence <- factor(data$us_valence, levels = c("positive","negative"))

library(lme4)
library(ggeffects)

contrasts(data$us_valence) <- "contr.sum"                   # = effects coding (i.e. sum-to-zero contrasts)
cntr <- center <- function(x) { x - mean(x, na.rm = TRUE) } # = function for centering

model <- lmer(
  formula = rating ~ (cntr(a) + cntr(b) + cntr(D) + cntr(Cpos) + cntr(Cneg) + cntr(dpos) + cntr(dneg)) * us_valence + (1 | id)
  , data = data
)
summary(model)

ggpredict(model, terms = ~ dpos * Cpos * us_valence) |>
  plot(rawdata = TRUE)

ggpredict(model, terms = ~ dneg * Cneg * us_valence) |>
  plot(rawdata = TRUE)
```

```{r}
# regression 3

id <- rep(1:length(para_ratings$url.srid),each = 2)
us_valence <- rep(c("positive","negative"),7)

regression_data <- data.frame(id = id
                              , us_valence = us_valence)

regression_data$order <- NA

regression_data$rating <- NA
regression_data$a <- NA
regression_data$b <- NA
regression_data$D <- NA
regression_data$C <- NA
regression_data$d <- NA

for(i in 1:nrow(regression_data)){
  tmp_id <- regression_data$id[i]
  if(regression_data$us_valence[i] == "positive"){
    regression_data$rating[i] <- para_ratings$positive[tmp_id]
    regression_data$a[i] <- para_ratings$a[tmp_id]
    regression_data$b[i] <- para_ratings$b[tmp_id]
    regression_data$D[i] <- para_ratings$Dn[tmp_id]
    regression_data$C[i] <- para_ratings$Cpos[tmp_id]
    regression_data$d[i] <- para_ratings$dpos[tmp_id]
  }
    if(regression_data$us_valence[i] == "negative"){
    regression_data$rating[i] <- para_ratings$negative[tmp_id]
    regression_data$a[i] <- para_ratings$a[tmp_id]
    regression_data$b[i] <- para_ratings$b[tmp_id]
    regression_data$D[i] <- para_ratings$Dn[tmp_id]
    regression_data$C[i] <- para_ratings$Cneg[tmp_id]
    regression_data$d[i] <- para_ratings$dneg[tmp_id]
  }
}

data <- regression_data
data$us_valence <- factor(data$us_valence, levels = c("positive","negative"))

library(lme4)
library(ggeffects)

contrasts(data$us_valence) <- "contr.sum"                   # = effects coding (i.e. sum-to-zero contrasts)
cntr <- center <- function(x) { x - mean(x, na.rm = TRUE) } # = function for centering

model <- lmer(
  formula = rating ~ (cntr(a) + cntr(b) + cntr(d) + cntr(D) + cntr(C)) * us_valence + (1 | id)
  , data = data
)
summary(model)

ggpredict(model, terms = ~ d * C * us_valence) |>
  plot(rawdata = TRUE)

ggpredict(model, terms = ~ C * d * us_valence) |>
  plot(rawdata = TRUE)




# 
cor.test(para_ratings$Dn,para_ratings$dist)
cor.test(para_ratings$Dn,para_ratings$positive)
cor.test(para_ratings$Dn,para_ratings$negative)
# 
cor.test(para_ratings$a,para_ratings$dist)
cor.test(para_ratings$a,para_ratings$positive)
cor.test(para_ratings$a,para_ratings$negative)
# 
cor.test(para_ratings$b,para_ratings$dist)
cor.test(para_ratings$b,para_ratings$positive)
cor.test(para_ratings$b,para_ratings$negative)
# 
cor.test(para_ratings$Cneg,para_ratings$dist)
cor.test(para_ratings$Cneg,para_ratings$positive)
cor.test(para_ratings$Cneg,para_ratings$negative)
# 
cor.test(para_ratings$Cpos,para_ratings$dist)
cor.test(para_ratings$Cpos,para_ratings$positive)
cor.test(para_ratings$Cpos,para_ratings$negative)
# 
cor.test(para_ratings$dpos,para_ratings$dist)
cor.test(para_ratings$dpos,para_ratings$positive)
cor.test(para_ratings$dpos,para_ratings$negative)
# 
cor.test(para_ratings$dneg,para_ratings$dist)
cor.test(para_ratings$dneg,para_ratings$positive)
cor.test(para_ratings$dneg,para_ratings$negative)

saveRDS(para_ratings, file = "ind_par_rate_KB.rds")

```

```{r}

parameters_long <- tidyr::pivot_longer(
  individual_parameters
  , cols = all_of(parameter_names)
  , names_to = c("parameter")
)

parameters_wide <- tidyr::pivot_wider(
  parameters_long
  , id_cols = c("url.srid")
  , names_from = "parameter"
)

ratings_with_parameters <- merge(agg_data_d, parameters_wide, by = c("url.srid"))

```

```{r}
#contrasts(ratings_with_parameters$US_valence) <- "contr.sum"
#contrasts(ratings_with_parameters$relation_type) <- "contr.sum"
#contrasts(ratings_with_parameters$relation_pair) <- "contr.sum"
center <- function(x) { x - mean(x, na.rm = TRUE) }

# trying to predict ratings of CS+
linear_model_pos <- lm(
  positive ~ center(Dn) + center(Cpos) + center(dpos) + center(a) + center(b)
  , data = ratings_with_parameters
)

summary(linear_model_pos)

linear_model_pos_allP <- lm(
  positive ~ center(Dn) + center(Cpos) + center(dpos) + center(Cneg) + center(dneg) + center(a) + center(b)
  , data = ratings_with_parameters
)

summary(linear_model_pos_allP)

# trying to predict ratings of CS-
linear_model_neg <- lm(
  negative ~ center(Dn) + center(Cneg) + center(dneg) + center(a) + center(b)
  , data = ratings_with_parameters
)

summary(linear_model_neg)

linear_model_neg_allP <- lm(
  negative ~ center(Dn) + center(Cpos) + center(dpos) + center(Cneg) + center(dneg) + center(a) + center(b)
  , data = ratings_with_parameters
)

summary(linear_model_neg_allP)

# trying to predict ratings of distractors
linear_model_dist_allP <- lm(
  dist ~ center(Dn) + center(Cpos) + center(dpos) + center(Cneg) + center(dneg) + center(a) + center(b)
  , data = ratings_with_parameters
)

summary(linear_model_dist_allP)

linear_model_dist_posP <- lm(
  dist ~ center(Dn) + center(Cpos) + center(dpos) + center(a) + center(b)
  , data = ratings_with_parameters
)

summary(linear_model_dist_posP)

linear_model_dist_negP <- lm(
  dist ~ center(Dn) + center(Cneg) + center(dneg) + center(a) + center(b)
  , data = ratings_with_parameters
)

summary(linear_model_dist_negP)





```




```{r}
extract_modelfit <- function(x) {
  data.frame(
    T1_observed    = median(x$T1.obs)
    , T1_predicted = median(x$T1.pred)
    , T1_ppp       = x$T1.p
  )
}

extract_modelfitT2 <- function(x) {
  data.frame(
    T2_observed    = median(x$T2.obs)
    , T2_predicted = median(x$T2.pred)
    , T2_ppp       = x$T2.p
  )
}

saveRDS(
      object = list(
        mod_mpt_summary = summary(mod_mpt)
        , model_1_fit_T1 = extract_modelfit(mod_mpt_ppp)
        , model_1_fit_T2 = extract_modelfitT2(mod_mpt_ppp)
      )
      , file =  "mod_mpt_fit_short.rds"
      )

saveRDS(
      object = list(mod_mpt_fit = mod_mpt_ppp)
      , file =  "model_mpt_fit_long.rds"
      )


#individual_parameters <- as.data.frame(getParam(model_1, parameter = "theta"))
#individual_parameters$id <- 1:nrow(individual_parameters)
#agg_data <- aggregate(eval_rating ~ us_valence + relation + id, data = data_1, FUN = mean)
#para_ratings <- merge(agg_data, individual_parameters, by = "id")


```

# One-step procedure for parameter estimation and correlations

```{r}

mpt_mod_1step <- traitMPT(eqnfile="KW_wsw_model.eqn",
                            data=mpt_data,
                            covData=ratings_with_parameters,
                            predStructure=list("Cpos ; positive",
                                               "dpos ; positive",
                                               "Cneg ; negative",
                                               "dneg ; negative"),
                            n.iter=4000,
                            n.adapt=2000,
                            n.thin=40, # less thinning => more precise Bayes factors
                            n.burnin=2000,
                            n.chain=4,
                            restrictions = list("Dn=Dpos=Dneg","G=0.25"),
                            #IVprec = IVprec,
                            ppp = 2000,
                            #modelfilename = "JAGS_CNI_TimeMedian.txt",
                            #parEstFile = "summary_CNI_TimeMedian.txt"
                          )

```

